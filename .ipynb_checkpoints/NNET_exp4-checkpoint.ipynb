{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "* Replace those special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "# from __future__ import print_function\n",
    "np.random.seed(786)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D, AveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier,  KerasRegressor\n",
    "#Some classes\n",
    "#Functions we need - Feature Selector, Fasttext_Estimator, Preprocessing Transformer, Binary_Encoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from pandas.api.types import is_numeric_dtype, is_string_dtype\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    print(np.min(y_pred), np.max(y_pred))\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_sklearn = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "def get_obj_cols(df):\n",
    "    \"\"\"Return columns with object dtypes\"\"\"\n",
    "    obj_cols = []\n",
    "    for idx, dt in enumerate(df.dtypes):\n",
    "        if dt == 'object':\n",
    "            obj_cols.append(df.columns.values[idx])\n",
    "\n",
    "    return obj_cols\n",
    "\n",
    "\n",
    "def convert_input(X):\n",
    "    \"\"\"if input not a dataframe convert it to one\"\"\"\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        if isinstance(X, list):\n",
    "            X = pd.DataFrame(np.array(X))\n",
    "        elif isinstance(X, (np.generic, np.ndarray)):\n",
    "            X = pd.DataFrame(X)\n",
    "        elif isinstance(X, csr_matrix):\n",
    "            X = pd.SparseDataFrame(X)\n",
    "        else:\n",
    "            raise ValueError('Unexpected input type: %s' % (str(type(X))))\n",
    "\n",
    "        #X = X.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "    return X\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Class to do subset of features in sklearn pipeline\"\"\"\n",
    "    def __init__(self, cols=None, return_df=True, verbose=0):\n",
    "        self.cols = cols\n",
    "        self.return_df = return_df\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        #Do nothing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        #if the input dataset isn't already a dataframe, convert it to one\n",
    "        X = X.copy(deep=True)\n",
    "        X = convert_input(X)\n",
    "        X = X.loc[:, self.col]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Selecting columns are {}\".format(self.col))\n",
    "        if self.return_df:\n",
    "            return X\n",
    "        else:\n",
    "            return X.values\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, thresh=0, func=np.mean, add_to_orig=False):\n",
    "        self.cols = cols\n",
    "        self.thresh = thresh\n",
    "        self.func = func\n",
    "        self.add_to_orig = add_to_orig\n",
    "    \n",
    "    #@numba.jit        \n",
    "    def fit(self, X, y):\n",
    "        self.prior = self.func(y)\n",
    "        self._dict = {}\n",
    "        for col in self.cols:\n",
    "            if isinstance(col, (list, tuple)):\n",
    "                print('here')\n",
    "                tmp_df = X.loc[: ,col]\n",
    "                col = tuple(col)\n",
    "            else:\n",
    "                tmp_df = X.loc[: ,[col]]\n",
    "            tmp_df['y'] = y\n",
    "            print(tmp_df.columns)\n",
    "            #tmp_df = pd.DataFrame({'eval_col':X[col].values, 'y':y})\n",
    "            if isinstance(col, (list, tuple)):\n",
    "                print('here')\n",
    "                col = tuple(col)\n",
    "            self._dict[col] = tmp_df.groupby(col)['y'].apply(lambda x: \n",
    "                                self.func(x) if len(x) >= self.thresh  else self.prior).to_dict()\n",
    "                                \n",
    "            del tmp_df\n",
    "        return self\n",
    "    #@numba.jit\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for col in self.cols:\n",
    "            \n",
    "            if isinstance(col, (list, tuple)):\n",
    "                tmp_df = X.loc[:, col]\n",
    "                enc = tmp_df[col].apply(lambda x: self._dict[tuple(col)][tuple(x)]\n",
    "                                                                     if tuple(x) in self._dict[tuple(col)]\n",
    "                                                                     else self.prior, axis=1).values\n",
    "            else:\n",
    "                tmp_df = X.loc[:, [col]]\n",
    "                enc = tmp_df[col].apply(lambda x: self._dict[col][x]\n",
    "                                                                     if x in self._dict[col]\n",
    "                                                                     else self.prior).values\n",
    "            del tmp_df\n",
    "            X_transformed.append(enc)\n",
    "        \n",
    "        X_transformed = np.vstack(X_transformed).T\n",
    "        \n",
    "        if self.add_to_orig:\n",
    "            return np.concatenate((X.values, X_transformed), axis=1)\n",
    "            \n",
    "        else:\n",
    "            return X_transformed\n",
    "        \n",
    "def isiphonecase(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                                (series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "def isiphone6(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('6|six', flags=re.IGNORECASE) &\n",
    "                        ~(series.str.contains('plus|\\+', flags=re.IGNORECASE)) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone6p(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('6|six', flags=re.IGNORECASE) &\n",
    "                        series.str.contains('plus|\\+', flags=re.IGNORECASE) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone5(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('5|five', flags=re.IGNORECASE) &\n",
    "                        ~(series.str.contains('plus|\\+', flags=re.IGNORECASE)) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone5p(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('5|five', flags=re.IGNORECASE) &\n",
    "                        series.str.contains('plus|\\+', flags=re.IGNORECASE) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone7(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('7|seven', flags=re.IGNORECASE) &\n",
    "                        ~(series.str.contains('plus|\\+', flags=re.IGNORECASE)) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone7p(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('7|seven', flags=re.IGNORECASE) &\n",
    "                        series.str.contains('plus|\\+', flags=re.IGNORECASE) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "#Data reading function\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.)\n",
    "\n",
    "        \n",
    "def tokenize(text):\n",
    "    return text.lower().strip(string.punctuation).split()\n",
    "\n",
    "\n",
    "def read_data(in_path, out_path):\n",
    "    if False and os.path.exists(os.path.join(out_path, 'train_2.pkl')) and os.path.exists(os.path.join(out_path, 'test_2.pkl')):\n",
    "        train_data = pd.read_pickle(os.path.join(out_path, 'train_2.pkl'))\n",
    "        test_data  = pd.read_pickle(os.path.join(out_path, 'test_2.pkl'))\n",
    "        \n",
    "        return train_data, test_data\n",
    "    \n",
    "    else:\n",
    "        train_data = pd.read_table(os.path.join(in_path, 'train.tsv'))\n",
    "        test_data  = pd.read_table(os.path.join(in_path, 'test.tsv'))\n",
    "    \n",
    "        train_rows = len(train_data)\n",
    "        data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "    \n",
    "        data['cat1'] = data['category_name'].apply(lambda x: str(x).split('/')[0])\n",
    "        data['cat2'] = data['category_name'].apply(lambda x: str(x).split('/')[1] \n",
    "                                                   if len(str(x).split('/')) > 1 else -1)\n",
    "        data['cat3'] = data['category_name'].apply(lambda x: ' '.join(str(x).split('/')[2:]) \n",
    "                                                   if len(str(x).split('/')) > 2 else -1)\n",
    "        data.fillna(-1, inplace=True)\n",
    "        \n",
    "        print(\"Getting word/char len features\")\n",
    "        data['desc_words'] = data['item_description'].apply(lambda x: len(str(x).split()))\n",
    "        data['desc_chars'] = data['item_description'].apply(lambda x: len(str(x)))\n",
    "        data['name_words'] = data['name'].apply(lambda x: len(str(x).split()))\n",
    "        data['name_chars'] = data['name'].apply(len)\n",
    "        \n",
    "        \n",
    "        print(\"Get iphone features\")\n",
    "        data['iphone_case'] = isiphonecase(data['name'])\n",
    "        data['iphone6'] = isiphone6(data['name'])\n",
    "        data['iphone6p'] = isiphone6p(data['name'])\n",
    "        data['iphone5'] = isiphone5(data['name'])\n",
    "        data['iphone5p'] = isiphone5p(data['name'])\n",
    "        data['iphone7'] = isiphone7(data['name'])\n",
    "        data['iphone7p'] = isiphone7p(data['name'])\n",
    "        data['unlocked_phone'] = data.name.str.contains('unlocked', flags=re.IGNORECASE)\n",
    "        cat_cols = ['category_name', 'brand_name', 'cat1', 'cat2', 'cat3', 'item_condition_id']\n",
    "        for col in cat_cols:\n",
    "            data[col] = LabelEncoder().fit_transform(data[col].astype(str)) + 1\n",
    "            \n",
    "        print(\"Get count features\")\n",
    "        target_enc1 = TargetEncoder(cols=['brand_name'], func=len)\n",
    "        data['brand_counts'] = target_enc1.fit_transform(data[['brand_name']], data.price)\n",
    "        data['brand_counts'] = data['brand_counts']/data['brand_counts'].max()\n",
    "\n",
    "        target_enc2 = TargetEncoder(cols=['category_name'], func=len)\n",
    "        data['cat_counts'] = target_enc2.fit_transform(data[['category_name']], data.price)\n",
    "        data['cat_counts'] = data['cat_counts']/data['cat_counts'].max()\n",
    "        \n",
    "        target_enc3 = TargetEncoder(cols=['cat1'], func=len)\n",
    "        data['cat1_counts'] = target_enc3.fit_transform(data[['cat1']], data.price)\n",
    "        data['cat1_counts'] = data['cat1_counts']/data['cat1_counts'].max()\n",
    "        \n",
    "        target_enc4 = TargetEncoder(cols=['cat2'], func=len)\n",
    "        data['cat2_counts'] = target_enc4.fit_transform(data[['cat2']], data.price)\n",
    "        data['cat2_counts'] = data['cat2_counts']/data['cat2_counts'].max()\n",
    "        \n",
    "        target_enc5 = TargetEncoder(cols=['cat3'], func=len)\n",
    "        data['cat3_counts'] = target_enc5.fit_transform(data[['cat3']], data.price)\n",
    "        data['cat3_counts'] = data['cat3_counts']/data['cat3_counts'].max()\n",
    "        #tkn_desc = Tokenizer(50000)   \n",
    "        \n",
    "        #reg = re.compile('[^a-zA-Z0-9 ]')\n",
    "        data[\"plus_counts\"] = data[\"name\"].apply(lambda x: sum([(s == '+') | (s == '➕') for s in str(x)]))\n",
    "        data[\"ands_counts\"] = data[\"name\"].apply(lambda x: sum([(s == '&') | (s == ' and ') for s in str(x)]))\n",
    "        data[\"comma_counts\"] = data[\"name\"].apply(lambda x: sum([s == ',' for s in str(x)]))\n",
    "        for col in [\"name\", \"item_description\"]:\n",
    "            data[col] = data[col].str.replace(\"'\", '').replace('-', '').replace('\\+', ' ').replace('✨', ' ').replace('❤', ' ').replace('⚡', ' ')\n",
    "        \n",
    "        \n",
    "        for col in [\"desc_words\", \"desc_chars\", \"name_words\", \"name_chars\", \"plus_counts\", \"ands_counts\", \"comma_counts\"]:\n",
    "            data[col]  = data[col]/ data[col].max()\n",
    "            \n",
    "            \n",
    "        data['item_desc2gram'] = data.item_description.apply(lambda x: add_ngrams(x, 2))\n",
    "        print(\"Tokenizing data\")\n",
    "        tok_name  = Tokenizer(20000)\n",
    "        tok_name.fit_on_texts(data['name'].astype(str))\n",
    "        print(len(tok_name.word_index))\n",
    "        \n",
    "        tok_desc= Tokenizer(50000)\n",
    "        tok_desc.fit_on_texts(data['item_description'].astype(str))\n",
    "        print(len(tok_desc.word_index))\n",
    "        \n",
    "        tok_desc2 = Tokenizer(20000)\n",
    "        tok_desc2.fit_on_texts(data['item_desc2gram'].astype(str))\n",
    "        print(len(tok_desc2.word_index))\n",
    "        \n",
    "        data[\"name\"] = list(zip(sequence.pad_sequences(tok_name.texts_to_sequences(data.name.astype(str)),\n",
    "                                         maxlen=7, padding='post', truncating='post')))\n",
    "        \n",
    "        data[\"item_description\"] = list(zip(sequence.pad_sequences(tok_desc.texts_to_sequences(data.item_description.astype(str)),\n",
    "                                         maxlen=70, padding='post', truncating='post')))\n",
    "        \n",
    "        data[\"item_desc2gram\"] = list(zip(sequence.pad_sequences(tok_desc2.texts_to_sequences(data.item_desc2gram.astype(str)),\n",
    "                                         maxlen=30, padding='post', truncating='post')))\n",
    "        #tkn_desc = Tokenizer(50000)\n",
    "        #tkn_desc.fit_on_texts(data.item_description.astype(str))\n",
    "        #data['desc_seq'] = pad_sequences(tkn_desc.texts_to_sequences(data.item_description.astype(str)),\n",
    "        #                                 maxlen=100, padding='post', truncating='post')\n",
    "        \n",
    "        #tkn_name = Tokenizer(4000)\n",
    "        #tkn_name.fit_on_texts(data.name.astype(str))\n",
    "        #data['name_seq'] = pad_sequences(tkn_name.texts_to_sequences(data.name.astype(str)),\n",
    "        #                                 maxlen=6, padding='post', truncating='post')\n",
    "        \n",
    "        \n",
    "        train_data = data.loc[: train_rows - 1, :].reset_index(drop=True)\n",
    "        train_data = train_data.loc[(train_data.price >= 1) & (train_data.price <= 2000), :].reset_index(drop=True)\n",
    "        test_data  = data.loc[train_rows: , :].reset_index(drop=True)\n",
    "        \n",
    "        del train_data['test_id']\n",
    "        del test_data['train_id']\n",
    "        del data \n",
    "        test_data['test_id'] = test_data['test_id'].astype(int)\n",
    "        #train_data.to_pickle(os.path.join(out_path, 'train_2.pkl'))\n",
    "        #test_data.to_pickle(os.path.join(out_path, 'test_2.pkl'))\n",
    "        \n",
    "        return train_data, test_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM_NNRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, embed_cols=None, dense_cols=None, embed_dims=None, \n",
    "                 text_embed_cols=None, text_embed_seq_lens=None, \n",
    "                 text_embed_dims=None, \n",
    "                 #text_embed_tokenizers=None,\n",
    "                 num_layers=2, multiprocess=False,\n",
    "                layer_activations=None, layer_dims=None,layer_dropouts=None, epochs=20, batchsize=32,\n",
    "                optimizer_kwargs=None, val_size=0.1, verbose=1, seed=1,):\n",
    "        \n",
    "        self.embed_cols = embed_cols\n",
    "        self.dense_cols = dense_cols\n",
    "        self.embed_dims = embed_dims\n",
    "        self.text_embed_cols = text_embed_cols\n",
    "        self.text_embed_dims = text_embed_dims\n",
    "        #self.text_embed_tokenizers = text_embed_tokenizers\n",
    "        self.text_embed_seq_lens = text_embed_seq_lens\n",
    "        self.dense_dims = None\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_dims = layer_dims\n",
    "        self.layer_activations = layer_activations\n",
    "        self.layer_dropouts = layer_dropouts\n",
    "        self.epochs = epochs\n",
    "        self.batchsize = batchsize\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self.val_size = val_size\n",
    "        self.verbose = verbose\n",
    "        self.multiprocess = multiprocess\n",
    "        self.seed = seed\n",
    "        #self.optim = optim\n",
    "        self.model = None\n",
    "        if self.dense_cols:\n",
    "            self.dense_dims = len(self.dense_cols)\n",
    "            \n",
    "    def _splitX(self, X):\n",
    "        X_splits = []\n",
    "        \n",
    "        if self.embed_cols:\n",
    "            for col in self.embed_cols :\n",
    "                X_splits.append(X[col].values.reshape(X.shape[0], -1))\n",
    "                \n",
    "        if self.text_embed_cols:\n",
    "            for i, col in enumerate(self.text_embed_cols):\n",
    "                #max_features = self.text_embed_dims[i][0]\n",
    "                #max_len = self.text_embed_seq_lens[i]\n",
    "                #input_text = X[col].astype(str)\n",
    "                #x_train = tok.texts_to_sequences(input_text)\n",
    "                #print(np.mean([len(l) for l in x_train]))\n",
    "                #x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "                #X_splits.append(np.array(x_train).reshape(X.shape[0], -1))\n",
    "                X_splits.append(np.concatenate(X[col].values))\n",
    "                \n",
    "        if self.dense_cols:\n",
    "            X_splits.append(X[self.dense_cols].values.reshape(X.shape[0], -1))\n",
    "            \n",
    "        return X_splits\n",
    "    \n",
    "    \n",
    "    def _build_model(self):\n",
    "        model_inputs = []\n",
    "        model_layers = []\n",
    "        \n",
    "        if self.embed_cols:\n",
    "            for col, dim in zip(self.embed_cols, self.embed_dims):\n",
    "                x1 = Input( shape=(1,), name=col)\n",
    "                model_inputs.append(x1)\n",
    "                x1 = Embedding(input_dim=dim[0], output_dim=dim[1], )(x1)\n",
    "                #x1 = Dropout(0.1)(x1)\n",
    "                x1 = Reshape(target_shape=(dim[1],))(x1)\n",
    "                model_layers.append(x1)\n",
    "                \n",
    "        if self.text_embed_cols:\n",
    "            for col, dim, seq_len in zip(self.text_embed_cols, \n",
    "                                                self.text_embed_dims, \n",
    "                                                self.text_embed_seq_lens):\n",
    "                x3 = Input( shape=(seq_len,))\n",
    "                model_inputs.append(x3)\n",
    "                x3 = Embedding(input_dim=dim[0], output_dim=dim[1], input_length=seq_len)(x3)\n",
    "                x3 = GlobalAveragePooling1D()(x3)\n",
    "                x3 = Reshape(target_shape=(dim[1],))(x3)\n",
    "                model_layers.append(x3)\n",
    "                \n",
    "        if self.dense_cols:\n",
    "            x2 = Input( shape=(self.dense_dims, ), name='dense_cols')\n",
    "            model_inputs.append(x2)\n",
    "            model_layers.append(x2)\n",
    "        print(model_layers)\n",
    "        x = concatenate(model_layers)\n",
    "        \n",
    "        if self.num_layers > 0:\n",
    "            for dim, drops in zip(self.layer_dims, self.layer_dropouts):\n",
    "                x = BatchNormalization()(x)\n",
    "                x = Dropout(rate=drops)(x)\n",
    "                x = Dense(dim, kernel_initializer='he_normal')(x)\n",
    "                x = LeakyReLU()(x)\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.05)(x)\n",
    "        output = Dense(1, activation='linear', kernel_initializer='he_normal')(x)\n",
    "        \n",
    "        model = Model(inputs=model_inputs, outputs=output)\n",
    "        #print(model.summary())\n",
    "        #adam = Nadam(lr=0.002, schedule_decay=0.02)\n",
    "        adam = Adam(lr=0.005, decay=0.001)\n",
    "        #adam = SGD(lr=0.01, nesterov=True, momentum=0.9, decay=0.003)\n",
    "        #adam = RMSprop(lr=0.01, decay=0.006)\n",
    "        #adam = self.optim\n",
    "        model.compile(optimizer=adam, loss='mean_squared_error' )\n",
    "        \n",
    "        return model \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = self._build_model()\n",
    "        if self.val_size > 0:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.val_size, random_state=self.seed)\n",
    "            print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "            \n",
    "            callbacks= [ModelCheckpoint(\"embed_NN_\"+str(self.seed)+\".check\", save_best_only=True, verbose=1)]\n",
    "            if self.multiprocess == False:\n",
    "                self.model.fit(self._splitX(X_train), y_train, batch_size=self.batchsize, epochs=self.epochs,\n",
    "                               verbose=self.verbose,\n",
    "                              validation_data=(self._splitX(X_val), y_val), shuffle=True,\n",
    "                              callbacks=callbacks)\n",
    "            else:\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.val_size, random_state=1)\n",
    "\n",
    "        else:\n",
    "            self.model.fit(self._splitX(X), y, batch_size=self.batchsize, epochs=self.epochs,\n",
    "               verbose=self.verbose, shuffle=True)\n",
    "\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        \n",
    "        if self.model:\n",
    "            model = load_model(\"embed_NN_\"+str(self.seed)+\".check\")\n",
    "            y_hat = model.predict(self._splitX(X))\n",
    "        else:\n",
    "            raise ValueError(\"Model not fit yet\")\n",
    "            \n",
    "        return y_hat\n",
    "        \n",
    "def add_ngrams(text, ngram=2):\n",
    "    word_list = str(text).lower().split(' ')\n",
    "    out_list = [''.join(word_list[i:i+ngram]) for i in range(len(word_list))]\n",
    "    return ' '.join(out_list[:-1])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting word/char len features\n",
      "Get iphone features\n",
      "Get count features\n",
      "Index(['brand_name', 'y'], dtype='object')\n",
      "Index(['category_name', 'y'], dtype='object')\n",
      "Index(['cat1', 'y'], dtype='object')\n",
      "Index(['cat2', 'y'], dtype='object')\n",
      "Index(['cat3', 'y'], dtype='object')\n",
      "Tokenizing data\n",
      "144600\n",
      "247101\n",
      "3722477\n",
      "(1481658, 32) (693359, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>train_id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>...</th>\n",
       "      <th>unlocked_phone</th>\n",
       "      <th>brand_counts</th>\n",
       "      <th>cat_counts</th>\n",
       "      <th>cat1_counts</th>\n",
       "      <th>cat2_counts</th>\n",
       "      <th>cat3_counts</th>\n",
       "      <th>plus_counts</th>\n",
       "      <th>ands_counts</th>\n",
       "      <th>comma_counts</th>\n",
       "      <th>item_desc2gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>831</td>\n",
       "      <td>3</td>\n",
       "      <td>([12, 63, 68, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>([2640, 4709, 5000, 57, 15, 4, 56],)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252631</td>\n",
       "      <td>0.141360</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.252631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>([16, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3891</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>([24, 2964, 10, 5, 34, 17, 1, 195, 50, 19, 900...</td>\n",
       "      <td>([5720, 12909, 10218, 1572, 0, 0, 0],)</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.185101</td>\n",
       "      <td>0.055355</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>([199, 82, 31, 757, 2440, 10598, 2061, 3185, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4590</td>\n",
       "      <td>1279</td>\n",
       "      <td>1</td>\n",
       "      <td>([532, 87, 8, 3, 4621, 11, 250, 1, 3, 956, 108...</td>\n",
       "      <td>([3863, 6141, 197, 0, 0, 0, 0],)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.338477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798175</td>\n",
       "      <td>0.338567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>([1323, 71, 11781, 9302, 6552, 192, 13181, 151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>([6, 8, 59, 193, 6670, 188, 4, 20, 141, 1058, ...</td>\n",
       "      <td>([118, 1600, 11506, 0, 0, 0, 0],)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217378</td>\n",
       "      <td>0.102457</td>\n",
       "      <td>0.187833</td>\n",
       "      <td>0.217378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>([36, 49, 35, 507, 128, 1905, 13, 1, 1, 138, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1206</td>\n",
       "      <td>1</td>\n",
       "      <td>([745, 8, 6178, 11, 1693, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>([3525, 45, 912, 139, 0, 0, 0],)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458721</td>\n",
       "      <td>0.328417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>([4317, 6769, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_name  category_name  item_condition_id  \\\n",
       "0           3            831                  3   \n",
       "1        3891             88                  3   \n",
       "2        4590           1279                  1   \n",
       "3           3            505                  1   \n",
       "4           3           1206                  1   \n",
       "\n",
       "                                    item_description  \\\n",
       "0  ([12, 63, 68, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  ([24, 2964, 10, 5, 34, 17, 1, 195, 50, 19, 900...   \n",
       "2  ([532, 87, 8, 3, 4621, 11, 250, 1, 3, 956, 108...   \n",
       "3  ([6, 8, 59, 193, 6670, 188, 4, 20, 141, 1058, ...   \n",
       "4  ([745, 8, 6178, 11, 1693, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                     name  price  shipping  train_id  cat1  \\\n",
       "0    ([2640, 4709, 5000, 57, 15, 4, 56],)   10.0         1       0.0     6   \n",
       "1  ([5720, 12909, 10218, 1572, 0, 0, 0],)   52.0         0       1.0     2   \n",
       "2        ([3863, 6141, 197, 0, 0, 0, 0],)   10.0         1       2.0    10   \n",
       "3       ([118, 1600, 11506, 0, 0, 0, 0],)   35.0         1       3.0     4   \n",
       "4        ([3525, 45, 912, 139, 0, 0, 0],)   44.0         0       4.0    10   \n",
       "\n",
       "   cat2                        ...                          unlocked_phone  \\\n",
       "0   104                        ...                                   False   \n",
       "1    32                        ...                                   False   \n",
       "2   105                        ...                                   False   \n",
       "3    57                        ...                                   False   \n",
       "4    60                        ...                                   False   \n",
       "\n",
       "   brand_counts  cat_counts  cat1_counts  cat2_counts  cat3_counts  \\\n",
       "0      1.000000    0.252631     0.141360     0.154083     0.252631   \n",
       "1      0.000139    0.016111     0.185101     0.055355     0.016111   \n",
       "2      0.002936    0.338477     1.000000     0.798175     0.338567   \n",
       "3      1.000000    0.217378     0.102457     0.187833     0.217378   \n",
       "4      1.000000    0.328417     1.000000     0.458721     0.328417   \n",
       "\n",
       "   plus_counts  ands_counts  comma_counts  \\\n",
       "0          0.0          0.0           0.0   \n",
       "1          0.0          0.0           0.0   \n",
       "2          0.0          0.0           0.0   \n",
       "3          0.0          0.0           0.0   \n",
       "4          0.0          0.0           0.0   \n",
       "\n",
       "                                      item_desc2gram  \n",
       "0  ([16, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  ([199, 82, 31, 757, 2440, 10598, 2061, 3185, 8...  \n",
       "2  ([1323, 71, 11781, 9302, 6552, 192, 13181, 151...  \n",
       "3  ([36, 49, 35, 507, 128, 1905, 13, 1, 1, 138, 1...  \n",
       "4  ([4317, 6769, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data\n",
    "train_data, test_data = read_data(\"../input\", \"./\")\n",
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data\n",
    "y = np.log1p(train_data.price)\n",
    "\n",
    "cvlist= list(KFold(5, random_state=786).split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_1/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_2/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_3/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_4/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_5/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_6/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_7/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_8/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_9/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.5729Epoch 00001: val_loss improved from inf to 0.26137, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 15s 13us/step - loss: 0.5728 - val_loss: 0.2614\n",
      "Epoch 2/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.2023Epoch 00002: val_loss improved from 0.26137 to 0.18594, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 11us/step - loss: 0.2022 - val_loss: 0.1859\n",
      "Epoch 3/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1757Epoch 00003: val_loss improved from 0.18594 to 0.18098, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 11us/step - loss: 0.1757 - val_loss: 0.1810\n",
      "Epoch 4/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1611Epoch 00004: val_loss improved from 0.18098 to 0.17872, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.1611 - val_loss: 0.1787\n",
      "Epoch 5/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1503Epoch 00005: val_loss improved from 0.17872 to 0.17865, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 11us/step - loss: 0.1503 - val_loss: 0.1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_10/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_11/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_12/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_13/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_14/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_15/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_16/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_17/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_18/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_2:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.5770Epoch 00001: val_loss improved from inf to 0.26107, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.5768 - val_loss: 0.2611\n",
      "Epoch 2/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.2033Epoch 00002: val_loss improved from 0.26107 to 0.18642, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 11us/step - loss: 0.2033 - val_loss: 0.1864\n",
      "Epoch 3/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1767Epoch 00003: val_loss improved from 0.18642 to 0.18173, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.1766 - val_loss: 0.1817\n",
      "Epoch 4/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1611Epoch 00004: val_loss improved from 0.18173 to 0.18099, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.1611 - val_loss: 0.1810\n",
      "Epoch 5/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1505Epoch 00005: val_loss improved from 0.18099 to 0.17929, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.1505 - val_loss: 0.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_19/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_20/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_21/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_22/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_23/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_24/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_25/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_26/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_27/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_4:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.5828Epoch 00001: val_loss improved from inf to 0.25670, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 15s 13us/step - loss: 0.5821 - val_loss: 0.2567\n",
      "Epoch 2/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.2012Epoch 00002: val_loss improved from 0.25670 to 0.18476, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.2012 - val_loss: 0.1848\n",
      "Epoch 3/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1750Epoch 00003: val_loss improved from 0.18476 to 0.18106, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.1750 - val_loss: 0.1811\n",
      "Epoch 4/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1599Epoch 00004: val_loss improved from 0.18106 to 0.17819, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.1599 - val_loss: 0.1782\n",
      "Epoch 5/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1487Epoch 00005: val_loss improved from 0.17819 to 0.17634, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 13s 12us/step - loss: 0.1487 - val_loss: 0.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_28/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_29/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_30/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_31/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_32/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_33/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_34/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_35/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_36/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_6:0' shape=(?, 21) dtype=float32>]\n",
      "(1155693, 32) (29634, 32) (1155693,) (29634,)\n",
      "Train on 1155693 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.5664Epoch 00001: val_loss improved from inf to 0.25755, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 15s 13us/step - loss: 0.5662 - val_loss: 0.2575\n",
      "Epoch 2/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.2039Epoch 00002: val_loss improved from 0.25755 to 0.18501, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 13s 12us/step - loss: 0.2039 - val_loss: 0.1850\n",
      "Epoch 3/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.1767Epoch 00003: val_loss improved from 0.18501 to 0.18098, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 13s 12us/step - loss: 0.1767 - val_loss: 0.1810\n",
      "Epoch 4/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.1615Epoch 00004: val_loss improved from 0.18098 to 0.17934, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 13s 11us/step - loss: 0.1615 - val_loss: 0.1793\n",
      "Epoch 5/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.1504Epoch 00005: val_loss improved from 0.17934 to 0.17922, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 13s 12us/step - loss: 0.1504 - val_loss: 0.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_37/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_38/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_39/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_40/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_41/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_42/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_43/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_44/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_45/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_8:0' shape=(?, 21) dtype=float32>]\n",
      "(1155693, 32) (29634, 32) (1155693,) (29634,)\n",
      "Train on 1155693 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.5633Epoch 00001: val_loss improved from inf to 0.24411, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 16s 14us/step - loss: 0.5625 - val_loss: 0.2441\n",
      "Epoch 2/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.2000Epoch 00002: val_loss improved from 0.24411 to 0.18430, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 13s 12us/step - loss: 0.2000 - val_loss: 0.1843\n",
      "Epoch 3/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.1737Epoch 00003: val_loss improved from 0.18430 to 0.18008, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 13s 12us/step - loss: 0.1737 - val_loss: 0.1801\n",
      "Epoch 4/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.1592Epoch 00004: val_loss improved from 0.18008 to 0.17758, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 13s 12us/step - loss: 0.1592 - val_loss: 0.1776\n",
      "Epoch 5/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.1483Epoch 00005: val_loss did not improve\n",
      "1155693/1155693 [==============================] - 13s 12us/step - loss: 0.1483 - val_loss: 0.1787\n",
      "0.1052371 9.489991\n",
      "0.42088114175697794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.2min finished\n"
     ]
    }
   ],
   "source": [
    "nnet1 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n",
    "                  embed_dims=[(6000, 40),(1500, 30), (6,4), (16,4), (121, 10), (900, 20)],\n",
    "                  text_embed_cols=['name', 'item_description', \n",
    "                                   'item_desc2gram'\n",
    "                                  ],\n",
    "                  text_embed_dims=[(20000, 50), (50000, 50), \n",
    "                                   (20000, 50)\n",
    "                                  ],\n",
    "                  text_embed_seq_lens =[7, 70, \n",
    "                                        30\n",
    "                                       ],\n",
    "                  #text_embed_tokenizers = [tok_name, tok_desc, tok_desc2],\n",
    "                  dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars','name_words',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts',\n",
    "                              \"plus_counts\", \"comma_counts\", \"ands_counts\"\n",
    "                                  ],\n",
    "                  epochs=5,\n",
    "                  batchsize=2048 ,\n",
    "                  num_layers = 1,\n",
    "                  layer_dropouts=[0.15],\n",
    "                  layer_dims=[200],\n",
    "                  seed=1,\n",
    "                  val_size=0.025,\n",
    "                 )\n",
    "\n",
    "oof_preds1 = cross_val_predict(nnet1, X, y, verbose=10, cv=cvlist)\n",
    "score = rmse(y, oof_preds1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6403"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_46/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_47/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_48/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_49/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_50/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_51/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_52/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_53/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_54/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_10:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.5793Epoch 00001: val_loss improved from inf to 0.24709, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 17s 14us/step - loss: 0.5785 - val_loss: 0.2471\n",
      "Epoch 2/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.2043Epoch 00002: val_loss improved from 0.24709 to 0.18771, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.2042 - val_loss: 0.1877\n",
      "Epoch 3/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1781Epoch 00003: val_loss improved from 0.18771 to 0.18142, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1781 - val_loss: 0.1814\n",
      "Epoch 4/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1631Epoch 00004: val_loss improved from 0.18142 to 0.17932, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1631 - val_loss: 0.1793\n",
      "Epoch 5/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1525Epoch 00005: val_loss improved from 0.17932 to 0.17881, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1524 - val_loss: 0.1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_55/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_56/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_57/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_58/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_59/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_60/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_61/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_62/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_63/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_12:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.5685Epoch 00001: val_loss improved from inf to 0.24949, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 17s 15us/step - loss: 0.5672 - val_loss: 0.2495\n",
      "Epoch 2/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.2037Epoch 00002: val_loss improved from 0.24949 to 0.18645, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.2037 - val_loss: 0.1865\n",
      "Epoch 3/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1775Epoch 00003: val_loss improved from 0.18645 to 0.18149, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1775 - val_loss: 0.1815\n",
      "Epoch 4/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1623Epoch 00004: val_loss improved from 0.18149 to 0.17894, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1623 - val_loss: 0.1789\n",
      "Epoch 5/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1518Epoch 00005: val_loss did not improve\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1517 - val_loss: 0.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_64/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_65/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_66/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_67/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_68/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_69/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_70/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_71/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_72/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_14:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.5622Epoch 00001: val_loss improved from inf to 0.25335, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 17s 15us/step - loss: 0.5608 - val_loss: 0.2533\n",
      "Epoch 2/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1997Epoch 00002: val_loss improved from 0.25335 to 0.18601, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1997 - val_loss: 0.1860\n",
      "Epoch 3/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1740Epoch 00003: val_loss improved from 0.18601 to 0.18074, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1740 - val_loss: 0.1807\n",
      "Epoch 4/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1592Epoch 00004: val_loss improved from 0.18074 to 0.17812, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1592 - val_loss: 0.1781\n",
      "Epoch 5/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1479Epoch 00005: val_loss did not improve\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1479 - val_loss: 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_73/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_74/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_75/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_76/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_77/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_78/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_79/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_80/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_81/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_16:0' shape=(?, 21) dtype=float32>]\n",
      "(1155693, 32) (29634, 32) (1155693,) (29634,)\n",
      "Train on 1155693 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.5730Epoch 00001: val_loss improved from inf to 0.26741, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 18s 16us/step - loss: 0.5728 - val_loss: 0.2674\n",
      "Epoch 2/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.2001Epoch 00002: val_loss improved from 0.26741 to 0.18485, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.2001 - val_loss: 0.1849\n",
      "Epoch 3/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.1744Epoch 00003: val_loss improved from 0.18485 to 0.18220, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1744 - val_loss: 0.1822\n",
      "Epoch 4/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.1597Epoch 00004: val_loss improved from 0.18220 to 0.17843, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1597 - val_loss: 0.1784\n",
      "Epoch 5/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.1487Epoch 00005: val_loss improved from 0.17843 to 0.17790, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1487 - val_loss: 0.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  7.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_82/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_83/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_84/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_85/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_86/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_87/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_88/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_89/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_90/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_18:0' shape=(?, 21) dtype=float32>]\n",
      "(1155693, 32) (29634, 32) (1155693,) (29634,)\n",
      "Train on 1155693 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.5607Epoch 00001: val_loss improved from inf to 0.25006, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 18s 16us/step - loss: 0.5605 - val_loss: 0.2501\n",
      "Epoch 2/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.1984Epoch 00002: val_loss improved from 0.25006 to 0.18485, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1985 - val_loss: 0.1849\n",
      "Epoch 3/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.1727Epoch 00003: val_loss improved from 0.18485 to 0.17997, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1727 - val_loss: 0.1800\n",
      "Epoch 4/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.1577Epoch 00004: val_loss improved from 0.17997 to 0.17774, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1577 - val_loss: 0.1777\n",
      "Epoch 5/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.1465Epoch 00005: val_loss did not improve\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1466 - val_loss: 0.1795\n",
      "0.5895728 9.019329\n",
      "0.42061442324481424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.0min finished\n"
     ]
    }
   ],
   "source": [
    "nnet2 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n",
    "                  embed_dims=[(6000, 30),(1500, 25), (5,4), (15,4), (120, 10), (900, 20)],\n",
    "                  text_embed_cols=['name', 'item_description', 'item_desc2gram'],\n",
    "                  text_embed_dims=[(20000, 30), (50000, 30), (20000, 30)],\n",
    "                  text_embed_seq_lens =[7, 70, 30],\n",
    "                  #text_embed_tokenizers = [tok_name, tok_desc, tok_desc2],\n",
    "                  dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts'],\n",
    "                  epochs=4,\n",
    "                  batchsize=2048 ,\n",
    "                  num_layers = 1,\n",
    "                  layer_dropouts=[0.1],\n",
    "                  layer_dims=[100],\n",
    "                  seed=2,\n",
    "                  val_size=0.02\n",
    "                 )\n",
    "oof_preds2 = cross_val_predict(nnet1, X, y, verbose=10, cv=cvlist)\n",
    "score = rmse(y, oof_preds2)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_91/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_92/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_93/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_94/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_95/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_96/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_97/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_98/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_99/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_20:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.5513Epoch 00001: val_loss improved from inf to 0.25039, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 19s 16us/step - loss: 0.5506 - val_loss: 0.2504\n",
      "Epoch 2/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1996Epoch 00002: val_loss improved from 0.25039 to 0.18381, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1995 - val_loss: 0.1838\n",
      "Epoch 3/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1733Epoch 00003: val_loss improved from 0.18381 to 0.18343, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1733 - val_loss: 0.1834\n",
      "Epoch 4/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1579Epoch 00004: val_loss improved from 0.18343 to 0.17940, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1579 - val_loss: 0.1794\n",
      "Epoch 5/5\n",
      "1150976/1155692 [============================>.] - ETA: 0s - loss: 0.1467Epoch 00005: val_loss improved from 0.17940 to 0.17792, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1467 - val_loss: 0.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_100/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_101/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_102/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_103/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_104/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_105/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_106/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_107/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_108/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_22:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.5709Epoch 00001: val_loss improved from inf to 0.24995, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 19s 16us/step - loss: 0.5707 - val_loss: 0.2500\n",
      "Epoch 2/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.2010Epoch 00002: val_loss improved from 0.24995 to 0.18513, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.2010 - val_loss: 0.1851\n",
      "Epoch 3/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1750Epoch 00003: val_loss improved from 0.18513 to 0.18046, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1750 - val_loss: 0.1805\n",
      "Epoch 4/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1598Epoch 00004: val_loss improved from 0.18046 to 0.17837, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1598 - val_loss: 0.1784\n",
      "Epoch 5/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1487Epoch 00005: val_loss improved from 0.17837 to 0.17762, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1487 - val_loss: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_109/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_110/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_111/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_112/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_113/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_114/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_115/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_116/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_117/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_24:0' shape=(?, 21) dtype=float32>]\n",
      "(1155692, 32) (29634, 32) (1155692,) (29634,)\n",
      "Train on 1155692 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.5693Epoch 00001: val_loss improved from inf to 0.24754, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 20s 17us/step - loss: 0.5685 - val_loss: 0.2475\n",
      "Epoch 2/5\n",
      "1153024/1155692 [============================>.] - ETA: 0s - loss: 0.1999Epoch 00002: val_loss improved from 0.24754 to 0.18664, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1999 - val_loss: 0.1866\n",
      "Epoch 3/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1741Epoch 00003: val_loss improved from 0.18664 to 0.17915, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1741 - val_loss: 0.1791\n",
      "Epoch 4/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1591Epoch 00004: val_loss improved from 0.17915 to 0.17741, saving model to embed_NN_1.check\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1591 - val_loss: 0.1774\n",
      "Epoch 5/5\n",
      "1155072/1155692 [============================>.] - ETA: 0s - loss: 0.1482Epoch 00005: val_loss did not improve\n",
      "1155692/1155692 [==============================] - 14s 12us/step - loss: 0.1482 - val_loss: 0.1780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_118/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_119/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_120/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_121/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_122/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_123/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_124/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_125/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_126/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_26:0' shape=(?, 21) dtype=float32>]\n",
      "(1155693, 32) (29634, 32) (1155693,) (29634,)\n",
      "Train on 1155693 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.5535Epoch 00001: val_loss improved from inf to 0.26000, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 20s 17us/step - loss: 0.5522 - val_loss: 0.2600\n",
      "Epoch 2/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.2060Epoch 00002: val_loss improved from 0.26000 to 0.18496, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.2060 - val_loss: 0.1850\n",
      "Epoch 3/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.1777Epoch 00003: val_loss improved from 0.18496 to 0.18119, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1777 - val_loss: 0.1812\n",
      "Epoch 4/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.1617Epoch 00004: val_loss improved from 0.18119 to 0.17909, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1617 - val_loss: 0.1791\n",
      "Epoch 5/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.1497Epoch 00005: val_loss did not improve\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1497 - val_loss: 0.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  7.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_127/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_128/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_129/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_130/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_131/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_132/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_133/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_134/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_135/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_28:0' shape=(?, 21) dtype=float32>]\n",
      "(1155693, 32) (29634, 32) (1155693,) (29634,)\n",
      "Train on 1155693 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.5732Epoch 00001: val_loss improved from inf to 0.25469, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 20s 18us/step - loss: 0.5725 - val_loss: 0.2547\n",
      "Epoch 2/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.2015Epoch 00002: val_loss improved from 0.25469 to 0.18475, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.2015 - val_loss: 0.1848\n",
      "Epoch 3/5\n",
      "1153024/1155693 [============================>.] - ETA: 0s - loss: 0.1753Epoch 00003: val_loss improved from 0.18475 to 0.18165, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1753 - val_loss: 0.1817\n",
      "Epoch 4/5\n",
      "1150976/1155693 [============================>.] - ETA: 0s - loss: 0.1604Epoch 00004: val_loss improved from 0.18165 to 0.17800, saving model to embed_NN_1.check\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1604 - val_loss: 0.1780\n",
      "Epoch 5/5\n",
      "1155072/1155693 [============================>.] - ETA: 0s - loss: 0.1492Epoch 00005: val_loss did not improve\n",
      "1155693/1155693 [==============================] - 14s 12us/step - loss: 0.1492 - val_loss: 0.1794\n",
      "0.37621096 9.291104\n",
      "0.4207457878387253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.5min finished\n"
     ]
    }
   ],
   "source": [
    "nnet3 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n",
    "                  embed_dims=[(6000, 30),(1500, 20), (5,4), (15,4), (120, 10), (900, 20)],\n",
    "                  text_embed_cols=['name', 'item_description', 'item_desc2gram'],\n",
    "                  text_embed_dims=[(20000, 50), (50000, 50), (20000, 50)],\n",
    "                  text_embed_seq_lens =[7, 70, 30],\n",
    "                  #text_embed_tokenizers = [tok_name, tok_desc, tok_desc2],\n",
    "                  dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts'],\n",
    "                  epochs=4,\n",
    "                  batchsize=2048 ,\n",
    "                  num_layers = 1,\n",
    "                  layer_dropouts=[0.25],\n",
    "                  layer_dims=[200],\n",
    "                  seed=3,\n",
    "                  val_size=0.02,\n",
    "                 )\n",
    "oof_preds3 = cross_val_predict(nnet1, X, y, verbose=10, cv=cvlist)\n",
    "score = rmse(y, oof_preds3)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean, gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481658,)\n",
      "0.5323847 9.266808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41201856747624277"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_preds = np.mean(np.hstack((oof_preds1, oof_preds2, oof_preds3)), axis=1)\n",
    "print(oof_preds.shape)\n",
    "rmse(y, oof_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a1f1e9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.distplot(oof_preds)\n",
    "sns.distplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481658, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   43.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.988219376342803 4.961022181829234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   54.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   54.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4244249992307715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=50, max_depth=3, n_jobs=-1, min_samples_leaf=50)\n",
    "oof_X = np.hstack((oof_preds1, oof_preds2, oof_preds3))\n",
    "print(oof_X.shape)\n",
    "oof2 = cross_val_predict(rfr, oof_X, y , cv=5, verbose=10)\n",
    "rmse(y, oof2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Nadam lr=0.015, decay=0.005 - mean of 3 models is 0.4185 (0.429, 0.429, 0.428)\n",
    "#RMSProp lr=0.003, decay=0.005 - mean 0.420 (0.425, 0.426, 0.424)\n",
    "#RMSProp lr=0.01, decay=0.005 - mean 0.425 (0.434, 0.431, 0.430)\n",
    "#RMSProp lr=0.004, decay=0.004 - mean 0.421 (0.428, 0.429, 0.427) \n",
    "#Adam lr=0.003, decay=0.003 - mean -- (0.4)\n",
    "#With Nadam lr=0.012, decay=0.01 - mean of 3 models is 0.4175 (0.427, 0.428, 0.429)\n",
    "\n",
    "#Adam and features lr=0.005, decay=0.001, 0.4137 (0.4207, 0.4204, 0.4213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_136/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_137/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_138/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_139/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_140/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_141/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_142/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_143/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_144/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_30:0' shape=(?, 21) dtype=float32>]\n",
      "(1444616, 32) (37042, 32) (1444616,) (37042,)\n",
      "Train on 1444616 samples, validate on 37042 samples\n",
      "Epoch 1/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.5105Epoch 00001: val_loss improved from inf to 0.20131, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 24s 17us/step - loss: 0.5103 - val_loss: 0.2013\n",
      "Epoch 2/5\n",
      "1439744/1444616 [============================>.] - ETA: 0s - loss: 0.1957Epoch 00002: val_loss improved from 0.20131 to 0.17799, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1956 - val_loss: 0.1780\n",
      "Epoch 3/5\n",
      "1439744/1444616 [============================>.] - ETA: 0s - loss: 0.1730Epoch 00003: val_loss improved from 0.17799 to 0.17397, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1730 - val_loss: 0.1740\n",
      "Epoch 4/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.1602Epoch 00004: val_loss improved from 0.17397 to 0.17274, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1602 - val_loss: 0.1727\n",
      "Epoch 5/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.1503Epoch 00005: val_loss improved from 0.17274 to 0.17062, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1503 - val_loss: 0.1706\n",
      "Predicting on test data\n",
      "[<tf.Tensor 'reshape_145/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_146/Reshape:0' shape=(?, 25) dtype=float32>, <tf.Tensor 'reshape_147/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_148/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_149/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_150/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_151/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_152/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_153/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_32:0' shape=(?, 17) dtype=float32>]\n",
      "(1452024, 32) (29634, 32) (1452024,) (29634,)\n",
      "Train on 1452024 samples, validate on 29634 samples\n",
      "Epoch 1/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.5018Epoch 00001: val_loss improved from inf to 0.20689, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 21s 15us/step - loss: 0.5006 - val_loss: 0.2069\n",
      "Epoch 2/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1954Epoch 00002: val_loss improved from 0.20689 to 0.18119, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 15s 10us/step - loss: 0.1954 - val_loss: 0.1812\n",
      "Epoch 3/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1744Epoch 00003: val_loss improved from 0.18119 to 0.17511, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 14s 10us/step - loss: 0.1743 - val_loss: 0.1751\n",
      "Epoch 4/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1621Epoch 00004: val_loss improved from 0.17511 to 0.17479, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 14s 10us/step - loss: 0.1621 - val_loss: 0.1748\n",
      "Predicting on test data\n",
      "[<tf.Tensor 'reshape_154/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_155/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_156/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_157/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_158/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_159/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_160/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_161/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_162/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_34:0' shape=(?, 17) dtype=float32>]\n",
      "(1452024, 32) (29634, 32) (1452024,) (29634,)\n",
      "Train on 1452024 samples, validate on 29634 samples\n",
      "Epoch 1/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.5142Epoch 00001: val_loss improved from inf to 0.21044, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 24s 17us/step - loss: 0.5130 - val_loss: 0.2104\n",
      "Epoch 2/4\n",
      "1447936/1452024 [============================>.] - ETA: 0s - loss: 0.2053Epoch 00002: val_loss improved from 0.21044 to 0.18658, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.2053 - val_loss: 0.1866\n",
      "Epoch 3/4\n",
      "1449984/1452024 [============================>.] - ETA: 0s - loss: 0.1824Epoch 00003: val_loss improved from 0.18658 to 0.17833, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.1824 - val_loss: 0.1783\n",
      "Epoch 4/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1704Epoch 00004: val_loss improved from 0.17833 to 0.17602, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.1704 - val_loss: 0.1760\n",
      "Predicting on test data\n",
      "Write out submission\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "nnet1.fit(train_data, np.log1p(train_data.price) )\n",
    "print(\"Predicting on test data\")\n",
    "test_preds1 = nnet1.predict(test_data)\n",
    "\n",
    "nnet2.fit(train_data, np.log1p(train_data.price) )\n",
    "print(\"Predicting on test data\")\n",
    "test_preds2 = nnet2.predict(test_data)\n",
    "\n",
    "nnet3.fit(train_data, np.log1p(train_data.price) )\n",
    "print(\"Predicting on test data\")\n",
    "test_preds3 = nnet3.predict(test_data)\n",
    "\n",
    "test_preds = (1/3)*(test_preds1 + test_preds2 + test_preds3)\n",
    "print(\"Write out submission\")\n",
    "submission: pd.DataFrame = test_data[['test_id']]\n",
    "submission['price'] = np.expm1(test_preds)\n",
    "submission.price = submission.price.clip(3, 2000)\n",
    "submission.to_csv(\"embedding_nn_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
