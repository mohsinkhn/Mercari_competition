{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 5\n",
    "* Use gensim for phrase based tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import threading\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, QuantileTransformer\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "# from __future__ import print_function\n",
    "np.random.seed(786)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D, AveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier,  KerasRegressor\n",
    "#Some classes\n",
    "#Functions we need - Feature Selector, Fasttext_Estimator, Preprocessing Transformer, Binary_Encoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from pandas.api.types import is_numeric_dtype, is_string_dtype\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    print(np.min(y_pred), np.max(y_pred))\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_sklearn = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "def get_obj_cols(df):\n",
    "    \"\"\"Return columns with object dtypes\"\"\"\n",
    "    obj_cols = []\n",
    "    for idx, dt in enumerate(df.dtypes):\n",
    "        if dt == 'object':\n",
    "            obj_cols.append(df.columns.values[idx])\n",
    "\n",
    "    return obj_cols\n",
    "\n",
    "\n",
    "def convert_input(X):\n",
    "    \"\"\"if input not a dataframe convert it to one\"\"\"\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        if isinstance(X, list):\n",
    "            X = pd.DataFrame(np.array(X))\n",
    "        elif isinstance(X, (np.generic, np.ndarray)):\n",
    "            X = pd.DataFrame(X)\n",
    "        elif isinstance(X, csr_matrix):\n",
    "            X = pd.SparseDataFrame(X)\n",
    "        else:\n",
    "            raise ValueError('Unexpected input type: %s' % (str(type(X))))\n",
    "\n",
    "        #X = X.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "    return X\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Class to do subset of features in sklearn pipeline\"\"\"\n",
    "    def __init__(self, cols=None, return_df=True, verbose=0):\n",
    "        self.cols = cols\n",
    "        self.return_df = return_df\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        #Do nothing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        #if the input dataset isn't already a dataframe, convert it to one\n",
    "        X = X.copy(deep=True)\n",
    "        X = convert_input(X)\n",
    "        X = X.loc[:, self.col]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Selecting columns are {}\".format(self.col))\n",
    "        if self.return_df:\n",
    "            return X\n",
    "        else:\n",
    "            return X.values\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, thresh=0, func=np.mean, add_to_orig=False):\n",
    "        self.cols = cols\n",
    "        self.thresh = thresh\n",
    "        self.func = func\n",
    "        self.add_to_orig = add_to_orig\n",
    "    \n",
    "    #@numba.jit        \n",
    "    def fit(self, X, y):\n",
    "        self.prior = self.func(y)\n",
    "        self._dict = {}\n",
    "        for col in self.cols:\n",
    "            if isinstance(col, (list, tuple)):\n",
    "                print('here')\n",
    "                tmp_df = X.loc[: ,col]\n",
    "                col = tuple(col)\n",
    "            else:\n",
    "                tmp_df = X.loc[: ,[col]]\n",
    "            tmp_df['y'] = y\n",
    "            print(tmp_df.columns)\n",
    "            #tmp_df = pd.DataFrame({'eval_col':X[col].values, 'y':y})\n",
    "            if isinstance(col, (list, tuple)):\n",
    "                print('here')\n",
    "                col = tuple(col)\n",
    "            self._dict[col] = tmp_df.groupby(col)['y'].apply(lambda x: \n",
    "                                self.func(x) if len(x) >= self.thresh  else self.prior).to_dict()\n",
    "                                \n",
    "            del tmp_df\n",
    "        return self\n",
    "    #@numba.jit\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for col in self.cols:\n",
    "            \n",
    "            if isinstance(col, (list, tuple)):\n",
    "                tmp_df = X.loc[:, col]\n",
    "                enc = tmp_df[col].apply(lambda x: self._dict[tuple(col)][tuple(x)]\n",
    "                                                                     if tuple(x) in self._dict[tuple(col)]\n",
    "                                                                     else self.prior, axis=1).values\n",
    "            else:\n",
    "                tmp_df = X.loc[:, [col]]\n",
    "                enc = tmp_df[col].apply(lambda x: self._dict[col][x]\n",
    "                                                                     if x in self._dict[col]\n",
    "                                                                     else self.prior).values\n",
    "            del tmp_df\n",
    "            X_transformed.append(enc)\n",
    "        \n",
    "        X_transformed = np.vstack(X_transformed).T\n",
    "        \n",
    "        if self.add_to_orig:\n",
    "            return np.concatenate((X.values, X_transformed), axis=1)\n",
    "            \n",
    "        else:\n",
    "            return X_transformed\n",
    "        \n",
    "def isiphonecase(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                                (series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "def isiphone6(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('6|six', flags=re.IGNORECASE) &\n",
    "                        ~(series.str.contains('plus|\\+', flags=re.IGNORECASE)) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone6p(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('6|six', flags=re.IGNORECASE) &\n",
    "                        series.str.contains('plus|\\+', flags=re.IGNORECASE) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone5(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('5|five', flags=re.IGNORECASE) &\n",
    "                        ~(series.str.contains('plus|\\+', flags=re.IGNORECASE)) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone5p(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('5|five', flags=re.IGNORECASE) &\n",
    "                        series.str.contains('plus|\\+', flags=re.IGNORECASE) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone7(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('7|seven', flags=re.IGNORECASE) &\n",
    "                        ~(series.str.contains('plus|\\+', flags=re.IGNORECASE)) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def isiphone7p(series): return (series.str.contains('iphone', flags=re.IGNORECASE) & \n",
    "                        series.str.contains('7|seven', flags=re.IGNORECASE) &\n",
    "                        series.str.contains('plus|\\+', flags=re.IGNORECASE) &\n",
    "                                ~(series.str.contains('case', flags=re.IGNORECASE)) )\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c if unicodedata.category(c) not in ['So', 'Sm', 'Lo', 'Sc']\n",
    "        else ' '\n",
    "        for c in unicodedata.normalize('NFD', str(s))\n",
    "    )\n",
    "\n",
    "def remove_puncts(s):\n",
    "    trans_table = str.maketrans({s:' ' for s in string.punctuation})\n",
    "    return str(s).translate(trans_table)\n",
    "\n",
    "#Data reading function\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.)\n",
    "\n",
    "        \n",
    "def tokenize(text):\n",
    "    return text.lower().strip(string.punctuation).split()\n",
    "\n",
    "\n",
    "def read_data(in_path, out_path):\n",
    "    if False and os.path.exists(os.path.join(out_path, 'train_2.pkl')) and os.path.exists(os.path.join(out_path, 'test_2.pkl')):\n",
    "        train_data = pd.read_pickle(os.path.join(out_path, 'train_2.pkl'))\n",
    "        test_data  = pd.read_pickle(os.path.join(out_path, 'test_2.pkl'))\n",
    "        \n",
    "        return train_data, test_data\n",
    "    \n",
    "    else:\n",
    "        train_data = pd.read_table(os.path.join(in_path, 'train.tsv'))\n",
    "        test_data  = pd.read_table(os.path.join(in_path, 'test.tsv'))\n",
    "    \n",
    "        train_rows = len(train_data)\n",
    "        data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "    \n",
    "        data['cat1'] = data['category_name'].apply(lambda x: str(x).split('/')[0])\n",
    "        data['cat2'] = data['category_name'].apply(lambda x: str(x).split('/')[1] \n",
    "                                                   if len(str(x).split('/')) > 1 else -1)\n",
    "        data['cat3'] = data['category_name'].apply(lambda x: ' '.join(str(x).split('/')[2:]) \n",
    "                                                   if len(str(x).split('/')) > 2 else -1)\n",
    "        data.fillna(-1, inplace=True)\n",
    "        \n",
    "        print(\"Getting word/char len features\")\n",
    "        data['desc_words'] = data['item_description'].apply(lambda x: len(str(x).split()))\n",
    "        data['desc_chars'] = data['item_description'].apply(lambda x: len(str(x)))\n",
    "        data['name_words'] = data['name'].apply(lambda x: len(str(x).split()))\n",
    "        data['name_chars'] = data['name'].apply(len)\n",
    "        \n",
    "        \n",
    "        print(\"Get iphone features\")\n",
    "        data['iphone_case'] = isiphonecase(data['name'])\n",
    "        data['iphone6'] = isiphone6(data['name'])\n",
    "        data['iphone6p'] = isiphone6p(data['name'])\n",
    "        data['iphone5'] = isiphone5(data['name'])\n",
    "        data['iphone5p'] = isiphone5p(data['name'])\n",
    "        data['iphone7'] = isiphone7(data['name'])\n",
    "        data['iphone7p'] = isiphone7p(data['name'])\n",
    "        data['unlocked_phone'] = data.name.str.contains('unlocked', flags=re.IGNORECASE)\n",
    "        cat_cols = ['category_name', 'brand_name', 'cat1', 'cat2', 'cat3', 'item_condition_id']\n",
    "        for col in cat_cols:\n",
    "            data[col] = LabelEncoder().fit_transform(data[col].astype(str)) + 1\n",
    "            \n",
    "        print(\"Get count features\")\n",
    "        target_enc1 = TargetEncoder(cols=['brand_name'], func=len)\n",
    "        data['brand_counts'] = target_enc1.fit_transform(data[['brand_name']], data.price)\n",
    "        data['brand_counts'] = data['brand_counts']/data['brand_counts'].max()\n",
    "\n",
    "        target_enc2 = TargetEncoder(cols=['category_name'], func=len)\n",
    "        data['cat_counts'] = target_enc2.fit_transform(data[['category_name']], data.price)\n",
    "        data['cat_counts'] = data['cat_counts']/data['cat_counts'].max()\n",
    "        \n",
    "        target_enc3 = TargetEncoder(cols=['cat1'], func=len)\n",
    "        data['cat1_counts'] = target_enc3.fit_transform(data[['cat1']], data.price)\n",
    "        data['cat1_counts'] = data['cat1_counts']/data['cat1_counts'].max()\n",
    "        \n",
    "        target_enc4 = TargetEncoder(cols=['cat2'], func=len)\n",
    "        data['cat2_counts'] = target_enc4.fit_transform(data[['cat2']], data.price)\n",
    "        data['cat2_counts'] = data['cat2_counts']/data['cat2_counts'].max()\n",
    "        \n",
    "        target_enc5 = TargetEncoder(cols=['cat3'], func=len)\n",
    "        data['cat3_counts'] = target_enc5.fit_transform(data[['cat3']], data.price)\n",
    "        data['cat3_counts'] = data['cat3_counts']/data['cat3_counts'].max()\n",
    "        #tkn_desc = Tokenizer(50000)   \n",
    "        \n",
    "        #reg = re.compile('[^a-zA-Z0-9 ]')\n",
    "        data[\"plus_counts\"] = data[\"name\"].apply(lambda x: sum([(s == '+') | (s == '➕') for s in str(x)]))\n",
    "        data[\"ands_counts\"] = data[\"name\"].apply(lambda x: sum([(s == '&') | (s == ' and ') for s in str(x)]))\n",
    "        data[\"comma_counts\"] = data[\"name\"].apply(lambda x: sum([s == ',' for s in str(x)]))\n",
    "        data[\"all_counts\"] = data[\"plus_counts\"] + data[\"ands_counts\"] + data[\"comma_counts\"]\n",
    "        \n",
    "        for col in [\"name\", \"item_description\"]:\n",
    "            data[col] = data[col].str.replace(\"'\", '').replace('-', '').progress_apply(unicodeToAscii)\n",
    "            data[col] = data[col].progress_apply(remove_puncts)\n",
    "        \n",
    "        \n",
    "        for col in [\"desc_words\", \"desc_chars\", \"name_words\", \"name_chars\", \"plus_counts\", \n",
    "                    \"ands_counts\", \"comma_counts\", \"all_counts\"]:\n",
    "            data[col]  = data[col]/ data[col].max()\n",
    "            \n",
    "        data[\"name_description\"] = data[\"name\"] + ' ' + data[\"item_description\"]\n",
    "        #stoplist = set('for a of the and to in on yet it'.split())\n",
    "        #dictionary = corpora.Dictionary(line.lower().split() for line in data[\"name_description\"].values)\n",
    "        \n",
    "        #stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
    "        #         if stopword in dictionary.token2id]\n",
    "        \n",
    "        #dictionary.filter_tokens(stop_ids)  # remove stop words and words that appear only once\n",
    "        #dictionary.compactify()\n",
    "        #print(dictionary)\n",
    "        #sentence_stream = [doc.lower().split(\" \") for doc in data[\"name_description\"].tolist()]\n",
    "        #del data[\"name_description\"]\n",
    "        \n",
    "        #bigram = Phraser(Phrases(sentence_stream, min_count=10, threshold=10, common_terms=stoplist))\n",
    "        #tokenized_stream = [bigram[sent] for sent in sentence_stream]\n",
    "        #data[\"name\"] = data['name'].progress_apply(lambda x: str(x).lower().split())\n",
    "        #dictionary_name = corpora.Dictionary([bigram[sent] for sent in tqdm(data['name'].values)])\n",
    "        #print(dictionary_name)\n",
    "        #dictionary_name.filter_extremes(keep_n=25000)\n",
    "        ##dictionary_name.compactify()\n",
    "        #data[\"name\"] = list(zip(pad_sequences(data[\"name\"].progress_apply(lambda x: \n",
    "        #    dictionary_name.doc2idx(bigram[x])).values, maxlen=7, value=-1.0, padding='post', truncating='post') + 1))\n",
    "\n",
    "        #del dictionary_name, sentence_stream\n",
    "        \n",
    "        #data[\"item_description\"] = data['item_description'].progress_apply(lambda x: str(x).lower().split())\n",
    "        #dictionary_desc = corpora.Dictionary([bigram[sent] for sent in tqdm(data['item_description'].values)])\n",
    "        #print(dictionary_desc)\n",
    "        #dictionary_desc.filter_extremes(keep_n=80000)\n",
    "        #dictionary_desc.compactify()\n",
    "        #data[\"item_description\"] = list(zip(pad_sequences(data[\"item_description\"].progress_apply(lambda x: \n",
    "        #    dictionary_desc.doc2idx(bigram[x])).values, maxlen=70, value=-1.0, padding='post', truncating='post') + 1))\n",
    "        \n",
    "        #del dictionary_desc\n",
    "        data['item_desc2gram'] = data.item_description.apply(lambda x: add_ngrams(x, 2))\n",
    "        print(\"Tokenizing data\")\n",
    "        tok_name  = Tokenizer(20000)\n",
    "        tok_name.fit_on_texts(data['name'].astype(str))\n",
    "        print(len(tok_name.word_index))\n",
    "        \n",
    "        tok_desc= Tokenizer(100000)\n",
    "        tok_desc.fit_on_texts(data['item_description'].astype(str))\n",
    "        print(len(tok_desc.word_index))\n",
    "        \n",
    "        tok_desc2 = Tokenizer(10000)\n",
    "        tok_desc2.fit_on_texts(data['item_desc2gram'].astype(str))\n",
    "        print(len(tok_desc2.word_index))\n",
    "        \n",
    "        data[\"item_name\"] = list(zip(sequence.pad_sequences(tok_name.texts_to_sequences(data.item_description.astype(str)),\n",
    "                                         maxlen=20, padding='post', truncating='post')))\n",
    "        \n",
    "        data[\"name\"] = list(zip(sequence.pad_sequences(tok_name.texts_to_sequences(data.name.astype(str)),\n",
    "                                         maxlen=7, padding='post', truncating='post')))\n",
    "        \n",
    "        data[\"item_description\"] = list(zip(sequence.pad_sequences(tok_desc.texts_to_sequences(data.item_description.astype(str)),\n",
    "                                         maxlen=80, padding='post', truncating='post')))\n",
    "        \n",
    "        \n",
    "        data[\"item_desc2gram\"] = list(zip(sequence.pad_sequences(tok_desc2.texts_to_sequences(data.item_desc2gram.astype(str)),\n",
    "                                         maxlen=20, padding='post', truncating='post')))\n",
    "        #tkn_desc = Tokenizer(50000)\n",
    "        #tkn_desc.fit_on_texts(data.item_description.astype(str))\n",
    "        #data['desc_seq'] = pad_sequences(tkn_desc.texts_to_sequences(data.item_description.astype(str)),\n",
    "        #                                 maxlen=100, padding='post', truncating='post')\n",
    "        \n",
    "        #tkn_name = Tokenizer(4000)\n",
    "        #tkn_name.fit_on_texts(data.name.astype(str))\n",
    "        #data['name_seq'] = pad_sequences(tkn_name.texts_to_sequences(data.name.astype(str)),\n",
    "        #                                 maxlen=6, padding='post', truncating='post')\n",
    "        \n",
    "        \n",
    "        train_data = data.loc[: train_rows - 1, :].reset_index(drop=True)\n",
    "        train_data = train_data.loc[(train_data.price >= 3) & (train_data.price <= 2000), :].reset_index(drop=True)\n",
    "        test_data  = data.loc[train_rows: , :].reset_index(drop=True)\n",
    "        \n",
    "        del train_data['test_id']\n",
    "        del test_data['train_id']\n",
    "        del data \n",
    "        test_data['test_id'] = test_data['test_id'].astype(int)\n",
    "        #train_data.to_pickle(os.path.join(out_path, 'train_2.pkl'))\n",
    "        #test_data.to_pickle(os.path.join(out_path, 'test_2.pkl'))\n",
    "        \n",
    "        return train_data, test_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train  =pd.read_table(\"../input/train.tsv\")\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[\"name_description\"] = train[\"name\"].astype(str) + ' ' + train[\"item_description\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_stream = [doc.lower().split(\" \") for doc in tqdm(train[\"name_description\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#stoplist = set('for a of the and to in'.split())\n",
    "#bigram = Phrases(sentence_stream, min_count=5, threshold=10, common_terms=stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#dictionary = corpora.Dictionary([bigram[sent] for sent in sentence_stream])\n",
    "#print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del sentence_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#dictionary.filter_extremes(keep_n=200000)\n",
    "#print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.doc2idx(bigram[train.name.iloc[0].lower().split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#pad_sequences(train[\"name\"].progress_apply(lambda x: dictionary.doc2idx(bigram[x.lower().split()])).values, maxlen=7, value=-1.0, padding='post') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "class ZeroMaskedEntries(Layer):\n",
    "    \"\"\"\n",
    "    This layer is called after an Embedding layer.\n",
    "    It zeros out all of the masked-out embeddings.\n",
    "    It also swallows the mask without passing it on.\n",
    "    You can change this to default pass-on behavior as follows:\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        if not self.mask_zero:\n",
    "            return None\n",
    "        else:\n",
    "            return K.not_equal(x, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.support_mask = True\n",
    "        super(ZeroMaskedEntries, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.output_dim = input_shape[1]\n",
    "        self.repeat_dim = input_shape[2]\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        #print(mask.shape)\n",
    "        mask = K.cast(mask, 'float32')\n",
    "        mask = K.repeat(mask, self.repeat_dim)\n",
    "        #print(mask.shape)\n",
    "        mask = K.permute_dimensions(mask, (0, 2, 1))\n",
    "        return x * mask\n",
    "\n",
    "    def compute_mask(self, input_shape, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "def mask_aware_mean(x):\n",
    "    # recreate the masks - all zero rows have been masked\n",
    "    #mask = K.not_equal(K.sum(K.abs(x), axis=2, keepdims=True), 0)\n",
    "\n",
    "    # number of that rows are not all zeros\n",
    "    #n = K.sum(K.cast(mask, 'float32'), axis=1, keepdims=False)\n",
    "    # compute mask-aware mean of x\n",
    "    x_mean = K.sum(x, axis=1, keepdims=False)\n",
    "    #print(x_mean.shape)\n",
    "    return x_mean\n",
    "\n",
    "def mask_aware_mean_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3 \n",
    "    return (shape[0], shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM_NNRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, embed_cols=None, dense_cols=None, embed_dims=None, \n",
    "                 text_embed_cols=None, text_embed_seq_lens=None, \n",
    "                 text_embed_dims=None, \n",
    "                 #text_embed_tokenizers=None,\n",
    "                 num_layers=2, multiprocess=False,\n",
    "                layer_activations=None, layer_dims=None,layer_dropouts=None, epochs=20, batchsize=32,\n",
    "                optimizer_kwargs=None, val_size=0.1, verbose=1, seed=1, lr_lr=0.005, lr_decay=0.001):\n",
    "        \n",
    "        self.embed_cols = embed_cols\n",
    "        self.dense_cols = dense_cols\n",
    "        self.embed_dims = embed_dims\n",
    "        self.text_embed_cols = text_embed_cols\n",
    "        self.text_embed_dims = text_embed_dims\n",
    "        #self.text_embed_tokenizers = text_embed_tokenizers\n",
    "        self.text_embed_seq_lens = text_embed_seq_lens\n",
    "        self.dense_dims = None\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_dims = layer_dims\n",
    "        self.layer_activations = layer_activations\n",
    "        self.layer_dropouts = layer_dropouts\n",
    "        self.epochs = epochs\n",
    "        self.batchsize = batchsize\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self.val_size = val_size\n",
    "        self.verbose = verbose\n",
    "        self.multiprocess = multiprocess\n",
    "        self.seed = seed\n",
    "        self.lr_lr=lr_lr\n",
    "        self.lr_decay=lr_decay\n",
    "        #self.optim = optim\n",
    "        self.model = None\n",
    "        if self.dense_cols:\n",
    "            self.dense_dims = len(self.dense_cols)\n",
    "            \n",
    "    def _splitX(self, X):\n",
    "        X_splits = []\n",
    "        \n",
    "        if self.embed_cols:\n",
    "            for col in self.embed_cols :\n",
    "                X_splits.append(X[col].values.reshape(X.shape[0], -1))\n",
    "                \n",
    "        if self.text_embed_cols:\n",
    "            for i, col in enumerate(self.text_embed_cols):\n",
    "                #max_features = self.text_embed_dims[i][0]\n",
    "                #max_len = self.text_embed_seq_lens[i]\n",
    "                #input_text = X[col].astype(str)\n",
    "                #x_train = tok.texts_to_sequences(input_text)\n",
    "                #print(np.mean([len(l) for l in x_train]))\n",
    "                #x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "                #X_splits.append(np.array(x_train).reshape(X.shape[0], -1))\n",
    "                X_splits.append(np.concatenate(X[col].values))\n",
    "                \n",
    "        if self.dense_cols:\n",
    "            X_splits.append(X[self.dense_cols].values.reshape(X.shape[0], -1))\n",
    "            \n",
    "        return X_splits\n",
    "    \n",
    "    \n",
    "    def _build_model(self):\n",
    "        model_inputs = []\n",
    "        model_layers = []\n",
    "        \n",
    "        if self.embed_cols:\n",
    "            for col, dim in zip(self.embed_cols, self.embed_dims):\n",
    "                x1 = Input( shape=(1,), name=col)\n",
    "                model_inputs.append(x1)\n",
    "                x1 = Embedding(input_dim=dim[0], output_dim=dim[1], )(x1)\n",
    "                #x1 = Dropout(0.1)(x1)\n",
    "                x1 = Reshape(target_shape=(dim[1],))(x1)\n",
    "                model_layers.append(x1)\n",
    "                \n",
    "        if self.text_embed_cols:\n",
    "            for col, dim, seq_len in zip(self.text_embed_cols, \n",
    "                                                self.text_embed_dims, \n",
    "                                                self.text_embed_seq_lens):\n",
    "                x3 = Input( shape=(seq_len,))\n",
    "                model_inputs.append(x3)\n",
    "                x3 = Embedding(input_dim=dim[0], output_dim=dim[1], input_length=seq_len,\n",
    "                               )(x3)\n",
    "                #x3 = Bidirectional(GRU(32, return_sequences=True))(x3)\n",
    "                x3 = GlobalAveragePooling1D()(x3)\n",
    "                #x3 = GlobalAvgPool1D()(x3)\n",
    "                #x3 = Reshape(target_shape=(dim[1],))(x3)\n",
    "                #x3 = Flatten()(x3)\n",
    "                #x3 = ZeroMaskedEntries()(x3)\n",
    "                #x3 = Lambda(mask_aware_mean, mask_aware_mean_output_shape)(x3)\n",
    "                model_layers.append(x3)\n",
    "                \n",
    "        if self.dense_cols:\n",
    "            x2 = Input( shape=(self.dense_dims, ), name='dense_cols')\n",
    "            model_inputs.append(x2)\n",
    "            model_layers.append(x2)\n",
    "        print(model_layers)\n",
    "        x = concatenate(model_layers)\n",
    "        \n",
    "        if self.num_layers > 0:\n",
    "            for dim, drops in zip(self.layer_dims, self.layer_dropouts):\n",
    "                x = BatchNormalization()(x)\n",
    "                x = Dropout(rate=drops)(x)\n",
    "                x = Dense(dim, activation='selu',kernel_initializer='he_normal')(x)\n",
    "                x = PReLU()(x)\n",
    "        \n",
    "        #x = concatenate([x, *model_layers[:3]])\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "        #x = Dense(100, kernel_initializer='he_normal')(x)\n",
    "        #x = LeakyReLU()(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.03)(x)\n",
    "        output = Dense(1,  kernel_initializer='he_normal')(x)\n",
    "        \n",
    "        model = Model(inputs=model_inputs, outputs=output)\n",
    "        #print(model.summary())\n",
    "        #adam = Nadam(lr=0.002, schedule_decay=0.02)\n",
    "        adam = Adam(lr=self.lr_lr, decay=self.lr_decay)\n",
    "        #adam = SGD(lr=0.01, nesterov=True, momentum=0.9, decay=0.003)\n",
    "        #adam = RMSprop(lr=0.008, decay=0.006)\n",
    "        #adam = self.optim\n",
    "        model.compile(optimizer=adam, loss='mean_squared_error' )\n",
    "        \n",
    "        return model \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = self._build_model()\n",
    "        if self.val_size > 0:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.val_size, random_state=self.seed)\n",
    "            print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "            \n",
    "            callbacks= [ModelCheckpoint(\"embed_NN_\"+str(self.seed)+\".check\", save_best_only=True, verbose=1)]\n",
    "            if self.multiprocess == False:\n",
    "                self.model.fit(self._splitX(X_train), y_train, batch_size=self.batchsize, epochs=self.epochs,\n",
    "                               verbose=self.verbose,\n",
    "                              validation_data=(self._splitX(X_val), y_val), shuffle=True,\n",
    "                              callbacks=callbacks)\n",
    "            else:\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.val_size, random_state=1)\n",
    "\n",
    "        else:\n",
    "            self.model.fit(self._splitX(X), y, batch_size=self.batchsize, epochs=self.epochs,\n",
    "               verbose=self.verbose, shuffle=True)\n",
    "\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        \n",
    "        if self.model:\n",
    "            if self.val_size > 0:\n",
    "                model = load_model(\"embed_NN_\"+str(self.seed)+\".check\")\n",
    "                y_hat = model.predict(self._splitX(X))\n",
    "            else:\n",
    "                y_hat = self.model.predict(self._splitX(X))\n",
    "        else:\n",
    "            raise ValueError(\"Model not fit yet\")\n",
    "            \n",
    "        return y_hat\n",
    "        \n",
    "def add_ngrams(text, ngram=2):\n",
    "    word_list = str(text).lower().split(' ')\n",
    "    out_list = [''.join(word_list[i:i+ngram]) for i in range(len(word_list))]\n",
    "    return ' '.join(out_list[:-1])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting word/char len features\n",
      "Get iphone features\n",
      "Get count features\n",
      "Index(['brand_name', 'y'], dtype='object')\n",
      "Index(['category_name', 'y'], dtype='object')\n",
      "Index(['cat1', 'y'], dtype='object')\n",
      "Index(['cat2', 'y'], dtype='object')\n",
      "Index(['cat3', 'y'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2175894/2175894 [00:16<00:00, 129199.67it/s]\n",
      "100%|██████████| 2175894/2175894 [00:11<00:00, 182969.75it/s]\n",
      "100%|██████████| 2175894/2175894 [01:18<00:00, 27886.18it/s]\n",
      "100%|██████████| 2175894/2175894 [00:17<00:00, 125018.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data\n",
      "134841\n",
      "224064\n",
      "3720109\n",
      "(1481658, 35) (693359, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>train_id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>...</th>\n",
       "      <th>cat1_counts</th>\n",
       "      <th>cat2_counts</th>\n",
       "      <th>cat3_counts</th>\n",
       "      <th>plus_counts</th>\n",
       "      <th>ands_counts</th>\n",
       "      <th>comma_counts</th>\n",
       "      <th>all_counts</th>\n",
       "      <th>name_description</th>\n",
       "      <th>item_desc2gram</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>831</td>\n",
       "      <td>3</td>\n",
       "      <td>([12, 63, 68, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>([2641, 4717, 5005, 57, 15, 4, 56],)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141360</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.252631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL No descrip...</td>\n",
       "      <td>([14, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>([453, 1683, 13268, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3891</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>([24, 2955, 10, 5, 34, 17, 1, 196, 51, 19, 904...</td>\n",
       "      <td>([5721, 12851, 10190, 1572, 0, 0, 0],)</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185101</td>\n",
       "      <td>0.055355</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard This keyboard...</td>\n",
       "      <td>([195, 77, 27, 768, 2445, 1968, 3183, 8740, 33...</td>\n",
       "      <td>([1093, 1572, 972, 88, 819, 955, 8, 244, 252, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4590</td>\n",
       "      <td>1279</td>\n",
       "      <td>1</td>\n",
       "      <td>([532, 88, 8, 3, 4601, 11, 251, 1, 3, 954, 107...</td>\n",
       "      <td>([3866, 6142, 197, 0, 0, 0, 0],)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798175</td>\n",
       "      <td>0.338567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AVA VIV Blouse Adorable top with a hint of lac...</td>\n",
       "      <td>([1318, 68, 9390, 6607, 184, 5206, 35, 199, 15...</td>\n",
       "      <td>([1364, 19, 77, 156, 25, 84, 8, 156, 641, 4683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>([6, 8, 59, 195, 6630, 189, 4, 21, 142, 1056, ...</td>\n",
       "      <td>([119, 1603, 11469, 0, 0, 0, 0],)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102457</td>\n",
       "      <td>0.187833</td>\n",
       "      <td>0.217378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Leather Horse Statues New with tags  Leather h...</td>\n",
       "      <td>([30, 45, 24, 525, 124, 1898, 10, 1, 1, 132, 1...</td>\n",
       "      <td>([3, 77, 769, 119, 5179, 2586, 6, 136, 2134, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1206</td>\n",
       "      <td>1</td>\n",
       "      <td>([746, 8, 6145, 11, 1689, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>([3528, 45, 913, 138, 0, 0, 0],)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458721</td>\n",
       "      <td>0.328417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24K GOLD plated rose Complete with certificate...</td>\n",
       "      <td>([4337, 6842, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>([1058, 77, 16091, 25, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_name  category_name  item_condition_id  \\\n",
       "0           3            831                  3   \n",
       "1        3891             88                  3   \n",
       "2        4590           1279                  1   \n",
       "3           3            505                  1   \n",
       "4           3           1206                  1   \n",
       "\n",
       "                                    item_description  \\\n",
       "0  ([12, 63, 68, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  ([24, 2955, 10, 5, 34, 17, 1, 196, 51, 19, 904...   \n",
       "2  ([532, 88, 8, 3, 4601, 11, 251, 1, 3, 954, 107...   \n",
       "3  ([6, 8, 59, 195, 6630, 189, 4, 21, 142, 1056, ...   \n",
       "4  ([746, 8, 6145, 11, 1689, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                     name  price  shipping  train_id  cat1  \\\n",
       "0    ([2641, 4717, 5005, 57, 15, 4, 56],)   10.0         1       0.0     6   \n",
       "1  ([5721, 12851, 10190, 1572, 0, 0, 0],)   52.0         0       1.0     2   \n",
       "2        ([3866, 6142, 197, 0, 0, 0, 0],)   10.0         1       2.0    10   \n",
       "3       ([119, 1603, 11469, 0, 0, 0, 0],)   35.0         1       3.0     4   \n",
       "4        ([3528, 45, 913, 138, 0, 0, 0],)   44.0         0       4.0    10   \n",
       "\n",
       "   cat2                        ...                          cat1_counts  \\\n",
       "0   104                        ...                             0.141360   \n",
       "1    32                        ...                             0.185101   \n",
       "2   105                        ...                             1.000000   \n",
       "3    57                        ...                             0.102457   \n",
       "4    60                        ...                             1.000000   \n",
       "\n",
       "   cat2_counts  cat3_counts  plus_counts  ands_counts  comma_counts  \\\n",
       "0     0.154083     0.252631          0.0          0.0           0.0   \n",
       "1     0.055355     0.016111          0.0          0.0           0.0   \n",
       "2     0.798175     0.338567          0.0          0.0           0.0   \n",
       "3     0.187833     0.217378          0.0          0.0           0.0   \n",
       "4     0.458721     0.328417          0.0          0.0           0.0   \n",
       "\n",
       "   all_counts                                   name_description  \\\n",
       "0         0.0  MLB Cincinnati Reds T Shirt Size XL No descrip...   \n",
       "1         0.0  Razer BlackWidow Chroma Keyboard This keyboard...   \n",
       "2         0.0  AVA VIV Blouse Adorable top with a hint of lac...   \n",
       "3         0.0  Leather Horse Statues New with tags  Leather h...   \n",
       "4         0.0  24K GOLD plated rose Complete with certificate...   \n",
       "\n",
       "                                      item_desc2gram  \\\n",
       "0  ([14, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  ([195, 77, 27, 768, 2445, 1968, 3183, 8740, 33...   \n",
       "2  ([1318, 68, 9390, 6607, 184, 5206, 35, 199, 15...   \n",
       "3  ([30, 45, 24, 525, 124, 1898, 10, 1, 1, 132, 1...   \n",
       "4  ([4337, 6842, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                           item_name  \n",
       "0  ([453, 1683, 13268, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  ([1093, 1572, 972, 88, 819, 955, 8, 244, 252, ...  \n",
       "2  ([1364, 19, 77, 156, 25, 84, 8, 156, 641, 4683...  \n",
       "3  ([3, 77, 769, 119, 5179, 2586, 6, 136, 2134, 9...  \n",
       "4  ([1058, 77, 16091, 25, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data\n",
    "train_data, test_data = read_data(\"../input\", \"./\")\n",
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desc2len = train_data.item_desc2gram.apply(lambda x: sum([el > 0 for el in x]))\n",
    "#plt.hist(desc2len)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_feats=['shipping', 'desc_words', 'desc_chars', 'name_chars','name_words',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts',\n",
    "                              \"plus_counts\", \"comma_counts\", \"ands_counts\", 'all_counts',\n",
    "                                  ]\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "train_data[dense_feats] = scaler.fit_transform(train_data[dense_feats])\n",
    "test_data[dense_feats] = scaler.transform(test_data[dense_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data\n",
    "y = np.log1p(train_data.price)\n",
    "\n",
    "cvlist= list(KFold(5, random_state=786).split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet1 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n",
    "                  embed_dims=[(6000, 40),(1500, 40), (6,4), (16,4), (121, 10), (900, 20)],\n",
    "                  text_embed_cols=['name', 'item_description', \n",
    "                                   'item_desc2gram', 'item_name'\n",
    "                                  ],\n",
    "                  text_embed_dims=[(20000, 50), (100000, 60), \n",
    "                                   (10000, 20), (20000, 30)\n",
    "                                  ],\n",
    "                  text_embed_seq_lens =[7, 80, \n",
    "                                       20, 20\n",
    "                                       ],\n",
    "                  #text_embed_tokenizers = [tok_name, tok_desc, tok_desc2],\n",
    "                  dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars','name_words',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts',\n",
    "                              \"plus_counts\", \"comma_counts\", \"ands_counts\", 'all_counts',\n",
    "                                  ],\n",
    "                  epochs=5,\n",
    "                  batchsize=2048 ,\n",
    "                  num_layers = 1,\n",
    "                  layer_dropouts=[0.12],\n",
    "                  layer_dims=[200],\n",
    "                  seed=1,\n",
    "                  val_size=0.02,\n",
    "                       lr_lr=0.005,\n",
    "                       lr_decay=0.001\n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_115/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_116/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_117/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_118/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_119/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_120/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_77/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_78/Mean:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'global_average_pooling1d_79/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_80/Mean:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_36:0' shape=(?, 22) dtype=float32>]\n",
      "(1161619, 35) (23707, 35) (1161619,) (23707,)\n",
      "Train on 1161619 samples, validate on 23707 samples\n",
      "Epoch 1/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.5363Epoch 00001: val_loss improved from inf to 0.24283, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 21s 18us/step - loss: 0.5351 - val_loss: 0.2428\n",
      "Epoch 2/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1928Epoch 00002: val_loss improved from 0.24283 to 0.18332, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 12us/step - loss: 0.1929 - val_loss: 0.1833\n",
      "Epoch 3/5\n",
      "1159168/1161619 [============================>.] - ETA: 0s - loss: 0.1648Epoch 00003: val_loss improved from 0.18332 to 0.18119, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 11us/step - loss: 0.1648 - val_loss: 0.1812\n",
      "Epoch 4/5\n",
      "1159168/1161619 [============================>.] - ETA: 0s - loss: 0.1473Epoch 00004: val_loss improved from 0.18119 to 0.17806, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 11us/step - loss: 0.1472 - val_loss: 0.1781\n",
      "Epoch 5/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1344Epoch 00005: val_loss improved from 0.17806 to 0.17731, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 12us/step - loss: 0.1344 - val_loss: 0.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_121/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_122/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_123/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_124/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_125/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_126/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_81/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_82/Mean:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'global_average_pooling1d_83/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_84/Mean:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_38:0' shape=(?, 22) dtype=float32>]\n",
      "(1161619, 35) (23707, 35) (1161619,) (23707,)\n",
      "Train on 1161619 samples, validate on 23707 samples\n",
      "Epoch 1/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.5180Epoch 00001: val_loss improved from inf to 0.24746, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 22s 19us/step - loss: 0.5168 - val_loss: 0.2475\n",
      "Epoch 2/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1901Epoch 00002: val_loss improved from 0.24746 to 0.18238, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1901 - val_loss: 0.1824\n",
      "Epoch 3/5\n",
      "1161216/1161619 [============================>.] - ETA: 0s - loss: 0.1621Epoch 00003: val_loss improved from 0.18238 to 0.18103, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1621 - val_loss: 0.1810\n",
      "Epoch 4/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1443Epoch 00004: val_loss improved from 0.18103 to 0.17914, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 12us/step - loss: 0.1443 - val_loss: 0.1791\n",
      "Epoch 5/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1316Epoch 00005: val_loss improved from 0.17914 to 0.17822, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 12us/step - loss: 0.1316 - val_loss: 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_127/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_128/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_129/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_130/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_131/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_132/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_85/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_86/Mean:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'global_average_pooling1d_87/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_88/Mean:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_40:0' shape=(?, 22) dtype=float32>]\n",
      "(1161619, 35) (23707, 35) (1161619,) (23707,)\n",
      "Train on 1161619 samples, validate on 23707 samples\n",
      "Epoch 1/5\n",
      "1161216/1161619 [============================>.] - ETA: 0s - loss: 0.5251Epoch 00001: val_loss improved from inf to 0.24615, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 22s 19us/step - loss: 0.5250 - val_loss: 0.2462\n",
      "Epoch 2/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1878Epoch 00002: val_loss improved from 0.24615 to 0.18357, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 11us/step - loss: 0.1877 - val_loss: 0.1836\n",
      "Epoch 3/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1606Epoch 00003: val_loss improved from 0.18357 to 0.18097, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 11us/step - loss: 0.1605 - val_loss: 0.1810\n",
      "Epoch 4/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1432Epoch 00004: val_loss improved from 0.18097 to 0.17657, saving model to embed_NN_1.check\n",
      "1161619/1161619 [==============================] - 13s 11us/step - loss: 0.1432 - val_loss: 0.1766\n",
      "Epoch 5/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1305Epoch 00005: val_loss did not improve\n",
      "1161619/1161619 [==============================] - 13s 11us/step - loss: 0.1306 - val_loss: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_133/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_134/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_135/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_136/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_137/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_138/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_89/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_90/Mean:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'global_average_pooling1d_91/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_92/Mean:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_42:0' shape=(?, 22) dtype=float32>]\n",
      "(1161620, 35) (23707, 35) (1161620,) (23707,)\n",
      "Train on 1161620 samples, validate on 23707 samples\n",
      "Epoch 1/5\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.5422Epoch 00001: val_loss improved from inf to 0.24760, saving model to embed_NN_1.check\n",
      "1161620/1161620 [==============================] - 23s 19us/step - loss: 0.5410 - val_loss: 0.2476\n",
      "Epoch 2/5\n",
      "1159168/1161620 [============================>.] - ETA: 0s - loss: 0.1898Epoch 00002: val_loss improved from 0.24760 to 0.18482, saving model to embed_NN_1.check\n",
      "1161620/1161620 [==============================] - 13s 11us/step - loss: 0.1898 - val_loss: 0.1848\n",
      "Epoch 3/5\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.1626Epoch 00003: val_loss improved from 0.18482 to 0.18002, saving model to embed_NN_1.check\n",
      "1161620/1161620 [==============================] - 13s 11us/step - loss: 0.1626 - val_loss: 0.1800\n",
      "Epoch 4/5\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.1457Epoch 00004: val_loss did not improve\n",
      "1161620/1161620 [==============================] - 13s 11us/step - loss: 0.1458 - val_loss: 0.1800\n",
      "Epoch 5/5\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.1331Epoch 00005: val_loss did not improve\n",
      "1161620/1161620 [==============================] - 13s 11us/step - loss: 0.1331 - val_loss: 0.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_139/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_140/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_141/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_142/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_143/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_144/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_93/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_94/Mean:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'global_average_pooling1d_95/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_96/Mean:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_44:0' shape=(?, 22) dtype=float32>]\n",
      "(1161620, 35) (23707, 35) (1161620,) (23707,)\n",
      "Train on 1161620 samples, validate on 23707 samples\n",
      "Epoch 1/5\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.5530Epoch 00001: val_loss improved from inf to 0.24164, saving model to embed_NN_1.check\n",
      "1161620/1161620 [==============================] - 23s 20us/step - loss: 0.5518 - val_loss: 0.2416\n",
      "Epoch 2/5\n",
      "1161216/1161620 [============================>.] - ETA: 0s - loss: 0.1898Epoch 00002: val_loss improved from 0.24164 to 0.18187, saving model to embed_NN_1.check\n",
      "1161620/1161620 [==============================] - 13s 11us/step - loss: 0.1898 - val_loss: 0.1819\n",
      "Epoch 3/5\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.1618Epoch 00003: val_loss improved from 0.18187 to 0.17804, saving model to embed_NN_1.check\n",
      "1161620/1161620 [==============================] - 13s 11us/step - loss: 0.1618 - val_loss: 0.1780\n",
      "Epoch 4/5\n",
      "1159168/1161620 [============================>.] - ETA: 0s - loss: 0.1448Epoch 00004: val_loss improved from 0.17804 to 0.17767, saving model to embed_NN_1.check\n",
      "1161620/1161620 [==============================] - 13s 11us/step - loss: 0.1448 - val_loss: 0.1777\n",
      "Epoch 5/5\n",
      "1159168/1161620 [============================>.] - ETA: 0s - loss: 0.1324Epoch 00005: val_loss did not improve\n",
      "1161620/1161620 [==============================] - 14s 12us/step - loss: 0.1324 - val_loss: 0.1783\n",
      "0.67212605 8.143955\n",
      "0.4211291814858868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.4min finished\n"
     ]
    }
   ],
   "source": [
    "oof_preds1 = cross_val_predict(nnet1, X, y, verbose=10, cv=cvlist)\n",
    "score = rmse(y, oof_preds1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_means = train_data.groupby(\"category_name\")[\"price\"].mean().to_dict()\n",
    "train_data[\"cat_mean\"] = train_data.category_name.map(cat_means).fillna(17)\n",
    "train_data[\"rel_price\"] = train_data[\"price\"]/train_data[\"cat_mean\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_151/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_152/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_153/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_154/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_155/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_156/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_101/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_102/Mean:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'global_average_pooling1d_103/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_104/Mean:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_48:0' shape=(?, 22) dtype=float32>]\n",
      "(1452024, 37) (29634, 37) (1452024,) (29634,)\n",
      "Train on 1452024 samples, validate on 29634 samples\n",
      "Epoch 1/5\n",
      "1449984/1452024 [============================>.] - ETA: 0s - loss: 0.7360Epoch 00001: val_loss improved from inf to 0.86456, saving model to embed_NN_1.check\n",
      "1452024/1452024 [==============================] - 28s 19us/step - loss: 0.7356 - val_loss: 0.8646\n",
      "Epoch 2/5\n",
      "1447936/1452024 [============================>.] - ETA: 0s - loss: 0.5669Epoch 00002: val_loss improved from 0.86456 to 0.79189, saving model to embed_NN_1.check\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.5666 - val_loss: 0.7919\n",
      "Epoch 3/5\n",
      "1449984/1452024 [============================>.] - ETA: 0s - loss: 0.4710Epoch 00003: val_loss did not improve\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.4712 - val_loss: 0.7999\n",
      "Epoch 4/5\n",
      "1449984/1452024 [============================>.] - ETA: 0s - loss: 0.4039Epoch 00004: val_loss did not improve\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.4038 - val_loss: 0.8175\n",
      "Epoch 5/5\n",
      "1449984/1452024 [============================>.] - ETA: 0s - loss: 0.3566Epoch 00005: val_loss did not improve\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.3567 - val_loss: 0.8069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EM_NNRegressor(batchsize=2048,\n",
       "        dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars', 'name_words', 'iphone_case', 'iphone6', 'iphone6p', 'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone', 'brand_counts', 'cat_counts', 'cat1_counts', 'cat2_counts', 'cat3_counts', 'plus_counts', 'comma_counts', 'ands_counts', 'all_counts'],\n",
       "        embed_cols=['brand_name', 'category_name', 'item_condition_id', 'cat1', 'cat2', 'cat3'],\n",
       "        embed_dims=[(6000, 40), (1500, 40), (6, 4), (16, 4), (121, 10), (900, 20)],\n",
       "        epochs=5, layer_activations=None, layer_dims=[200],\n",
       "        layer_dropouts=[0.12], lr_decay=0.001, lr_lr=0.005,\n",
       "        multiprocess=False, num_layers=1, optimizer_kwargs=None, seed=1,\n",
       "        text_embed_cols=['name', 'item_description', 'item_desc2gram', 'item_name'],\n",
       "        text_embed_dims=[(20000, 50), (100000, 60), (10000, 20), (20000, 30)],\n",
       "        text_embed_seq_lens=[7, 80, 20, 20], val_size=0.02, verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_rel = train_data.apply(lambda row: row['price'] - cat_means[row[\"category_name\"]] if row['category_name'] in cat_means \n",
    "#                          else row[\"price\"] - 17, axis=1)\n",
    "nnet1.fit(train_data, train_data.rel_price )\n",
    "#print(\"Predicting on test data\")\n",
    "#test_preds3 = test_data[\"category_name\"].apply(lambda x: cat_means[x] if x in cat_means else 17) + nnet1.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-5fbdf4204c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_preds3\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mnnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rel_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_preds3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right, name, na_op)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_na_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         return construct_result(\n\u001b[1;32m    741\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0muse_numexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                              'b_value': b_value},\n\u001b[1;32m    109\u001b[0m                                  \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'safe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruediv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                  **eval_kwargs)\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'unknown type object'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0m_numexpr_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompiled_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mevaluate_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_preds3 =  (nnet1.predict(train_data) - 1)* train_data['rel_price']\n",
    "rmse(np.log1p(train_data.price), np.log1p(train_preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV, gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import dump\n",
    "\n",
    "def optimize_nn( X, y, cvlist, save_path=\"../input/\"):\n",
    "    space  = [(5, 80),                           # brand embeddings\n",
    "              (5, 80),                              # category embedding\n",
    "              (2, 10),                            # item condition embedding\n",
    "              (2, 10),                            # cat1 embedding\n",
    "              (2, 20),                             # cat2 embedding\n",
    "              (2, 80),                              # cat3 embedding\n",
    "              (20, 100),                         #name embedding\n",
    "              (20, 100),                         #desc embedding\n",
    "              (20, 100),                         #desc2 embedding\n",
    "              (10, 100),                         #name desc\n",
    "              (50, 500),                         #dense layer\n",
    "              (0.01, 0.5),                        #dense dropout \n",
    "              (0.001, 0.01),                      #lr\n",
    "              (0.00001, 0.01) ]                     #lr decay\n",
    "              \n",
    "    def objective(params):\n",
    "        gc.collect()\n",
    "        brand_dim, category_dim, condition_dim, cat1_dim, cat2_dim, cat3_dim, \\\n",
    "        name_dim, desc_dim, desc2_dim, namedesc_dim, dense_dim, dense_drop, lr, lr_decay = params\n",
    "        nnet2 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n",
    "                      embed_dims=[(6000, brand_dim),\n",
    "                                  (1500, category_dim), \n",
    "                                  (6, condition_dim), \n",
    "                                  (16,cat1_dim), \n",
    "                                  (121, cat2_dim), \n",
    "                                  (900, cat3_dim)],\n",
    "                      text_embed_cols=['name', 'item_description', 'item_desc2gram', 'item_name'],\n",
    "                      text_embed_dims=[(20000, name_dim), (100000, desc_dim), (10000, desc2_dim), (20000, namedesc_dim)],\n",
    "                      text_embed_seq_lens =[7, 80, 20, 20],\n",
    "                      #text_embed_cols=['name'],\n",
    "                      #text_embed_dims=[(50000, 80)],\n",
    "                      #text_embed_seq_lens =[10], \n",
    "                      dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts'],\n",
    "                      epochs=5,\n",
    "                      batchsize=2048,\n",
    "                      num_layers = 1,\n",
    "                      layer_dropouts=[dense_drop],\n",
    "                      layer_dims=[dense_dim],\n",
    "                      val_size=0,\n",
    "                      seed=786,\n",
    "                      lr_lr=lr,\n",
    "                      lr_decay=lr_decay,\n",
    "                     )\n",
    "        print(\"parameters...................\",params)\n",
    "        #scores = cross_val_score(nnet2, X, y, cv=cvlist, verbose=1, scoring=rmse_sklearn, n_jobs=1,\n",
    "        #                         pre_dispatch=None)\n",
    "        preds = cross_val_predict(nnet2, X, y, cv=cvlist, verbose=1, n_jobs=1, pre_dispatch=None)\n",
    "        gc.collect()\n",
    "        #score = np.mean(scores)\n",
    "        score = rmse(y,preds)\n",
    "        del nnet2, preds\n",
    "        print(\"score........................\", score)\n",
    "        #preds_test = est.set_params(**lgb_params).fit(X, y).predict_proba_corr(X_test)\n",
    "        #preds_dict = {'params':lgb_params, 'train_preds': preds, 'test_preds':preds_test}\n",
    "        #filepath = os.path.join(save_path, 'nn_'+str(score))\n",
    "        #with open(filepath, \"wb\") as f:\n",
    "        #    pickle.dump(preds_dict, f)\n",
    "        #print(\"Saved..............:\", filepath)\n",
    "        return score\n",
    "    gc.collect()\n",
    "    res = gp_minimize(objective,                  # the function to minimize\n",
    "                      space,                          # the bounds on each dimension of x\n",
    "                      acq_func=\"EI\",                  # the acquisition function\n",
    "                      n_calls=30,                     # the number of evaluations of f \n",
    "                      n_random_starts=5,             # the number of random initialization points\n",
    "                      random_state=786,\n",
    "                     verbose=True) \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "parameters................... [62, 28, 9, 5, 18, 8, 88, 79, 95, 53, 300, 0.17400593951308432, 0.003549846986806506, 0.0051158780373344835]\n",
      "[<tf.Tensor 'reshape_1/Reshape:0' shape=(?, 62) dtype=float32>, <tf.Tensor 'reshape_2/Reshape:0' shape=(?, 28) dtype=float32>, <tf.Tensor 'reshape_3/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_4/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_5/Reshape:0' shape=(?, 18) dtype=float32>, <tf.Tensor 'reshape_6/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'global_average_pooling1d_1/Mean:0' shape=(?, 88) dtype=float32>, <tf.Tensor 'global_average_pooling1d_2/Mean:0' shape=(?, 79) dtype=float32>, <tf.Tensor 'global_average_pooling1d_3/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_4/Mean:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'dense_cols:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.6776\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.2195\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1938\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1782\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1668\n",
      "[<tf.Tensor 'reshape_7/Reshape:0' shape=(?, 62) dtype=float32>, <tf.Tensor 'reshape_8/Reshape:0' shape=(?, 28) dtype=float32>, <tf.Tensor 'reshape_9/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_10/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_11/Reshape:0' shape=(?, 18) dtype=float32>, <tf.Tensor 'reshape_12/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'global_average_pooling1d_5/Mean:0' shape=(?, 88) dtype=float32>, <tf.Tensor 'global_average_pooling1d_6/Mean:0' shape=(?, 79) dtype=float32>, <tf.Tensor 'global_average_pooling1d_7/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_8/Mean:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'dense_cols_1:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.6900\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.2198\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 16s 14us/step - loss: 0.1947\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 16s 14us/step - loss: 0.1796\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 16s 14us/step - loss: 0.1684\n",
      "[<tf.Tensor 'reshape_13/Reshape:0' shape=(?, 62) dtype=float32>, <tf.Tensor 'reshape_14/Reshape:0' shape=(?, 28) dtype=float32>, <tf.Tensor 'reshape_15/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_16/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_17/Reshape:0' shape=(?, 18) dtype=float32>, <tf.Tensor 'reshape_18/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'global_average_pooling1d_9/Mean:0' shape=(?, 88) dtype=float32>, <tf.Tensor 'global_average_pooling1d_10/Mean:0' shape=(?, 79) dtype=float32>, <tf.Tensor 'global_average_pooling1d_11/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_12/Mean:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'dense_cols_2:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.7292\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.2202\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1959\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1809\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1699\n",
      "[<tf.Tensor 'reshape_19/Reshape:0' shape=(?, 62) dtype=float32>, <tf.Tensor 'reshape_20/Reshape:0' shape=(?, 28) dtype=float32>, <tf.Tensor 'reshape_21/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_22/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_23/Reshape:0' shape=(?, 18) dtype=float32>, <tf.Tensor 'reshape_24/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'global_average_pooling1d_13/Mean:0' shape=(?, 88) dtype=float32>, <tf.Tensor 'global_average_pooling1d_14/Mean:0' shape=(?, 79) dtype=float32>, <tf.Tensor 'global_average_pooling1d_15/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_16/Mean:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'dense_cols_3:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.6914\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.2235\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1974\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1813\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1698\n",
      "[<tf.Tensor 'reshape_25/Reshape:0' shape=(?, 62) dtype=float32>, <tf.Tensor 'reshape_26/Reshape:0' shape=(?, 28) dtype=float32>, <tf.Tensor 'reshape_27/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_28/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_29/Reshape:0' shape=(?, 18) dtype=float32>, <tf.Tensor 'reshape_30/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'global_average_pooling1d_17/Mean:0' shape=(?, 88) dtype=float32>, <tf.Tensor 'global_average_pooling1d_18/Mean:0' shape=(?, 79) dtype=float32>, <tf.Tensor 'global_average_pooling1d_19/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_20/Mean:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'dense_cols_4:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 17s 15us/step - loss: 0.6923\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.2198\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1945\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1788\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6479314 8.781342\n",
      "score........................ 0.42333140868143176\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 569.4418\n",
      "Function value obtained: 0.4233\n",
      "Current minimum: 0.4233\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "parameters................... [47, 53, 6, 7, 10, 33, 200, 193, 71, 13, 277, 0.4815519605755087, 0.006147014338805021, 0.004943473578961356]\n",
      "[<tf.Tensor 'reshape_31/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_32/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_33/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_34/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_35/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_36/Reshape:0' shape=(?, 33) dtype=float32>, <tf.Tensor 'global_average_pooling1d_21/Mean:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'global_average_pooling1d_22/Mean:0' shape=(?, 193) dtype=float32>, <tf.Tensor 'global_average_pooling1d_23/Mean:0' shape=(?, 71) dtype=float32>, <tf.Tensor 'global_average_pooling1d_24/Mean:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'dense_cols_5:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 22s 18us/step - loss: 0.6843\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.2262\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.2056\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.1937\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.1846\n",
      "[<tf.Tensor 'reshape_37/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_38/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_39/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_40/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_41/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_42/Reshape:0' shape=(?, 33) dtype=float32>, <tf.Tensor 'global_average_pooling1d_25/Mean:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'global_average_pooling1d_26/Mean:0' shape=(?, 193) dtype=float32>, <tf.Tensor 'global_average_pooling1d_27/Mean:0' shape=(?, 71) dtype=float32>, <tf.Tensor 'global_average_pooling1d_28/Mean:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'dense_cols_6:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 24s 20us/step - loss: 0.6994\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 23s 20us/step - loss: 0.2284\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 23s 20us/step - loss: 0.2075\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 24s 20us/step - loss: 0.1953\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 24s 20us/step - loss: 0.1865\n",
      "[<tf.Tensor 'reshape_43/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_44/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_45/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_46/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_47/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_48/Reshape:0' shape=(?, 33) dtype=float32>, <tf.Tensor 'global_average_pooling1d_29/Mean:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'global_average_pooling1d_30/Mean:0' shape=(?, 193) dtype=float32>, <tf.Tensor 'global_average_pooling1d_31/Mean:0' shape=(?, 71) dtype=float32>, <tf.Tensor 'global_average_pooling1d_32/Mean:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'dense_cols_7:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 25s 21us/step - loss: 0.5969\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 23s 20us/step - loss: 0.2264\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 23s 20us/step - loss: 0.2052\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 24s 20us/step - loss: 0.1926\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 23s 20us/step - loss: 0.1827\n",
      "[<tf.Tensor 'reshape_49/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_50/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_51/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_52/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_53/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_54/Reshape:0' shape=(?, 33) dtype=float32>, <tf.Tensor 'global_average_pooling1d_33/Mean:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'global_average_pooling1d_34/Mean:0' shape=(?, 193) dtype=float32>, <tf.Tensor 'global_average_pooling1d_35/Mean:0' shape=(?, 71) dtype=float32>, <tf.Tensor 'global_average_pooling1d_36/Mean:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'dense_cols_8:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 22s 19us/step - loss: 0.5863\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 21s 18us/step - loss: 0.2295\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 22s 18us/step - loss: 0.2089\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 21s 18us/step - loss: 0.1956\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 21s 18us/step - loss: 0.1860\n",
      "[<tf.Tensor 'reshape_55/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_56/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_57/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_58/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_59/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_60/Reshape:0' shape=(?, 33) dtype=float32>, <tf.Tensor 'global_average_pooling1d_37/Mean:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'global_average_pooling1d_38/Mean:0' shape=(?, 193) dtype=float32>, <tf.Tensor 'global_average_pooling1d_39/Mean:0' shape=(?, 71) dtype=float32>, <tf.Tensor 'global_average_pooling1d_40/Mean:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'dense_cols_9:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 24s 21us/step - loss: 0.6663\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 23s 20us/step - loss: 0.2259\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 23s 20us/step - loss: 0.2055\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 23s 20us/step - loss: 0.1929\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 24s 20us/step - loss: 0.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566272 8.70369\n",
      "score........................ 0.42974103525727214\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 722.0759\n",
      "Function value obtained: 0.4297\n",
      "Current minimum: 0.4233\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "parameters................... [57, 7, 7, 8, 13, 78, 172, 99, 56, 77, 284, 0.13738549904296662, 0.007624722428961093, 0.004925971826416672]\n",
      "[<tf.Tensor 'reshape_61/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_62/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_63/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_64/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_65/Reshape:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'reshape_66/Reshape:0' shape=(?, 78) dtype=float32>, <tf.Tensor 'global_average_pooling1d_41/Mean:0' shape=(?, 172) dtype=float32>, <tf.Tensor 'global_average_pooling1d_42/Mean:0' shape=(?, 99) dtype=float32>, <tf.Tensor 'global_average_pooling1d_43/Mean:0' shape=(?, 56) dtype=float32>, <tf.Tensor 'global_average_pooling1d_44/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_10:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.5487\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.2002\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1771\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1614\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1493\n",
      "[<tf.Tensor 'reshape_67/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_68/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_69/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_70/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_71/Reshape:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'reshape_72/Reshape:0' shape=(?, 78) dtype=float32>, <tf.Tensor 'global_average_pooling1d_45/Mean:0' shape=(?, 172) dtype=float32>, <tf.Tensor 'global_average_pooling1d_46/Mean:0' shape=(?, 99) dtype=float32>, <tf.Tensor 'global_average_pooling1d_47/Mean:0' shape=(?, 56) dtype=float32>, <tf.Tensor 'global_average_pooling1d_48/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_11:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 19s 16us/step - loss: 0.6660\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1920\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1703\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1562\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1455\n",
      "[<tf.Tensor 'reshape_73/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_74/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_75/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_76/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_77/Reshape:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'reshape_78/Reshape:0' shape=(?, 78) dtype=float32>, <tf.Tensor 'global_average_pooling1d_49/Mean:0' shape=(?, 172) dtype=float32>, <tf.Tensor 'global_average_pooling1d_50/Mean:0' shape=(?, 99) dtype=float32>, <tf.Tensor 'global_average_pooling1d_51/Mean:0' shape=(?, 56) dtype=float32>, <tf.Tensor 'global_average_pooling1d_52/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_12:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 19s 16us/step - loss: 0.5984\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1933\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1712\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1565\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 18s 15us/step - loss: 0.1459\n",
      "[<tf.Tensor 'reshape_79/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_80/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_81/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_82/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_83/Reshape:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'reshape_84/Reshape:0' shape=(?, 78) dtype=float32>, <tf.Tensor 'global_average_pooling1d_53/Mean:0' shape=(?, 172) dtype=float32>, <tf.Tensor 'global_average_pooling1d_54/Mean:0' shape=(?, 99) dtype=float32>, <tf.Tensor 'global_average_pooling1d_55/Mean:0' shape=(?, 56) dtype=float32>, <tf.Tensor 'global_average_pooling1d_56/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_13:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.5724\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1942\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1707\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1557\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1444\n",
      "[<tf.Tensor 'reshape_85/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_86/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_87/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_88/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_89/Reshape:0' shape=(?, 13) dtype=float32>, <tf.Tensor 'reshape_90/Reshape:0' shape=(?, 78) dtype=float32>, <tf.Tensor 'global_average_pooling1d_57/Mean:0' shape=(?, 172) dtype=float32>, <tf.Tensor 'global_average_pooling1d_58/Mean:0' shape=(?, 99) dtype=float32>, <tf.Tensor 'global_average_pooling1d_59/Mean:0' shape=(?, 56) dtype=float32>, <tf.Tensor 'global_average_pooling1d_60/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_14:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.6370\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1928\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1712\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1572\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 18s 15us/step - loss: 0.1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677895 9.512472\n",
      "score........................ 0.4231598383223651\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 618.5279\n",
      "Function value obtained: 0.4232\n",
      "Current minimum: 0.4232\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "parameters................... [39, 21, 10, 3, 5, 65, 158, 77, 57, 54, 237, 0.07152027193123939, 0.0036267193832712746, 0.008652961263048202]\n",
      "[<tf.Tensor 'reshape_91/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_92/Reshape:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'reshape_93/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_94/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_95/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_96/Reshape:0' shape=(?, 65) dtype=float32>, <tf.Tensor 'global_average_pooling1d_61/Mean:0' shape=(?, 158) dtype=float32>, <tf.Tensor 'global_average_pooling1d_62/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'global_average_pooling1d_63/Mean:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'global_average_pooling1d_64/Mean:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'dense_cols_15:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 19s 16us/step - loss: 0.6520\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.2158\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.1909\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.1752\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1639\n",
      "[<tf.Tensor 'reshape_97/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_98/Reshape:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'reshape_99/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_100/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_101/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_102/Reshape:0' shape=(?, 65) dtype=float32>, <tf.Tensor 'global_average_pooling1d_65/Mean:0' shape=(?, 158) dtype=float32>, <tf.Tensor 'global_average_pooling1d_66/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'global_average_pooling1d_67/Mean:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'global_average_pooling1d_68/Mean:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'dense_cols_16:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 19s 16us/step - loss: 0.7081\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.2237\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.1996\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.1847\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1734\n",
      "[<tf.Tensor 'reshape_103/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_104/Reshape:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'reshape_105/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_106/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_107/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_108/Reshape:0' shape=(?, 65) dtype=float32>, <tf.Tensor 'global_average_pooling1d_69/Mean:0' shape=(?, 158) dtype=float32>, <tf.Tensor 'global_average_pooling1d_70/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'global_average_pooling1d_71/Mean:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'global_average_pooling1d_72/Mean:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'dense_cols_17:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 19s 16us/step - loss: 0.6894\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.2180\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1936\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.1785\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 17s 15us/step - loss: 0.1679\n",
      "[<tf.Tensor 'reshape_109/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_110/Reshape:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'reshape_111/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_112/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_113/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_114/Reshape:0' shape=(?, 65) dtype=float32>, <tf.Tensor 'global_average_pooling1d_73/Mean:0' shape=(?, 158) dtype=float32>, <tf.Tensor 'global_average_pooling1d_74/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'global_average_pooling1d_75/Mean:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'global_average_pooling1d_76/Mean:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'dense_cols_18:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 19s 16us/step - loss: 0.6350\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 17s 15us/step - loss: 0.2237\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1981\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1822\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 17s 15us/step - loss: 0.1704\n",
      "[<tf.Tensor 'reshape_115/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_116/Reshape:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'reshape_117/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_118/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_119/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_120/Reshape:0' shape=(?, 65) dtype=float32>, <tf.Tensor 'global_average_pooling1d_77/Mean:0' shape=(?, 158) dtype=float32>, <tf.Tensor 'global_average_pooling1d_78/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'global_average_pooling1d_79/Mean:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'global_average_pooling1d_80/Mean:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'dense_cols_19:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 19s 16us/step - loss: 0.6631\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.2224\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1971\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 17s 15us/step - loss: 0.1815\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73029244 9.222692\n",
      "score........................ 0.42628856735531534\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 602.7614\n",
      "Function value obtained: 0.4263\n",
      "Current minimum: 0.4232\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "parameters................... [54, 39, 4, 7, 20, 61, 144, 145, 59, 21, 436, 0.3137056060605819, 0.006394293368325554, 0.008248084961561954]\n",
      "[<tf.Tensor 'reshape_121/Reshape:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'reshape_122/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_123/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_124/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_125/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_126/Reshape:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_81/Mean:0' shape=(?, 144) dtype=float32>, <tf.Tensor 'global_average_pooling1d_82/Mean:0' shape=(?, 145) dtype=float32>, <tf.Tensor 'global_average_pooling1d_83/Mean:0' shape=(?, 59) dtype=float32>, <tf.Tensor 'global_average_pooling1d_84/Mean:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'dense_cols_20:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 22s 19us/step - loss: 0.6757\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.2210\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.2033\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.1916\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.1837\n",
      "[<tf.Tensor 'reshape_127/Reshape:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'reshape_128/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_129/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_130/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_131/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_132/Reshape:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_85/Mean:0' shape=(?, 144) dtype=float32>, <tf.Tensor 'global_average_pooling1d_86/Mean:0' shape=(?, 145) dtype=float32>, <tf.Tensor 'global_average_pooling1d_87/Mean:0' shape=(?, 59) dtype=float32>, <tf.Tensor 'global_average_pooling1d_88/Mean:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'dense_cols_21:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 22s 18us/step - loss: 0.6431\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.2176\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.1988\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.1876\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.1792\n",
      "[<tf.Tensor 'reshape_133/Reshape:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'reshape_134/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_135/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_136/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_137/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_138/Reshape:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_89/Mean:0' shape=(?, 144) dtype=float32>, <tf.Tensor 'global_average_pooling1d_90/Mean:0' shape=(?, 145) dtype=float32>, <tf.Tensor 'global_average_pooling1d_91/Mean:0' shape=(?, 59) dtype=float32>, <tf.Tensor 'global_average_pooling1d_92/Mean:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'dense_cols_22:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 22s 18us/step - loss: 0.6258\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.2181\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 20s 16us/step - loss: 0.1994\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 19s 16us/step - loss: 0.1876\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 20s 17us/step - loss: 0.1794\n",
      "[<tf.Tensor 'reshape_139/Reshape:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'reshape_140/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_141/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_142/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_143/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_144/Reshape:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_93/Mean:0' shape=(?, 144) dtype=float32>, <tf.Tensor 'global_average_pooling1d_94/Mean:0' shape=(?, 145) dtype=float32>, <tf.Tensor 'global_average_pooling1d_95/Mean:0' shape=(?, 59) dtype=float32>, <tf.Tensor 'global_average_pooling1d_96/Mean:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'dense_cols_23:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 22s 19us/step - loss: 0.6948\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.2183\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.2005\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.1894\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.1812\n",
      "[<tf.Tensor 'reshape_145/Reshape:0' shape=(?, 54) dtype=float32>, <tf.Tensor 'reshape_146/Reshape:0' shape=(?, 39) dtype=float32>, <tf.Tensor 'reshape_147/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_148/Reshape:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'reshape_149/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_150/Reshape:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_97/Mean:0' shape=(?, 144) dtype=float32>, <tf.Tensor 'global_average_pooling1d_98/Mean:0' shape=(?, 145) dtype=float32>, <tf.Tensor 'global_average_pooling1d_99/Mean:0' shape=(?, 59) dtype=float32>, <tf.Tensor 'global_average_pooling1d_100/Mean:0' shape=(?, 21) dtype=float32>, <tf.Tensor 'dense_cols_24:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 23s 19us/step - loss: 0.6788\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.2181\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.2002\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.1893\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 20s 17us/step - loss: 0.1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6603354 9.292091\n",
      "score........................ 0.4268437789040523\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 683.5477\n",
      "Function value obtained: 0.4268\n",
      "Current minimum: 0.4232\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "parameters................... [47, 53, 2, 6, 20, 5, 36, 191, 95, 100, 291, 0.33612278318953953, 0.005780024051773614, 0.006220966407099599]\n",
      "[<tf.Tensor 'reshape_151/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_152/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_153/Reshape:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'reshape_154/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_155/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_156/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'global_average_pooling1d_101/Mean:0' shape=(?, 36) dtype=float32>, <tf.Tensor 'global_average_pooling1d_102/Mean:0' shape=(?, 191) dtype=float32>, <tf.Tensor 'global_average_pooling1d_103/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_104/Mean:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'dense_cols_25:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 23s 20us/step - loss: 0.5426\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.2312\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.2100\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.1960\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.1854\n",
      "[<tf.Tensor 'reshape_157/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_158/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_159/Reshape:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'reshape_160/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_161/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_162/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'global_average_pooling1d_105/Mean:0' shape=(?, 36) dtype=float32>, <tf.Tensor 'global_average_pooling1d_106/Mean:0' shape=(?, 191) dtype=float32>, <tf.Tensor 'global_average_pooling1d_107/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_108/Mean:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'dense_cols_26:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 23s 20us/step - loss: 0.5898\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.2333\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.2125\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 21s 18us/step - loss: 0.1992\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 22s 18us/step - loss: 0.1894\n",
      "[<tf.Tensor 'reshape_163/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_164/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_165/Reshape:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'reshape_166/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_167/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_168/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'global_average_pooling1d_109/Mean:0' shape=(?, 36) dtype=float32>, <tf.Tensor 'global_average_pooling1d_110/Mean:0' shape=(?, 191) dtype=float32>, <tf.Tensor 'global_average_pooling1d_111/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_112/Mean:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'dense_cols_27:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 26s 22us/step - loss: 0.7464\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 23s 19us/step - loss: 0.2275\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 23s 19us/step - loss: 0.2080\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 23s 19us/step - loss: 0.1955\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 22s 19us/step - loss: 0.1868\n",
      "[<tf.Tensor 'reshape_169/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_170/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_171/Reshape:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'reshape_172/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_173/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_174/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'global_average_pooling1d_113/Mean:0' shape=(?, 36) dtype=float32>, <tf.Tensor 'global_average_pooling1d_114/Mean:0' shape=(?, 191) dtype=float32>, <tf.Tensor 'global_average_pooling1d_115/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_116/Mean:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'dense_cols_28:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 25s 21us/step - loss: 0.7618\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 23s 19us/step - loss: 0.2307\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 23s 19us/step - loss: 0.2112\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 23s 19us/step - loss: 0.1991\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 23s 19us/step - loss: 0.1904\n",
      "[<tf.Tensor 'reshape_175/Reshape:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'reshape_176/Reshape:0' shape=(?, 53) dtype=float32>, <tf.Tensor 'reshape_177/Reshape:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'reshape_178/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'reshape_179/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_180/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'global_average_pooling1d_117/Mean:0' shape=(?, 36) dtype=float32>, <tf.Tensor 'global_average_pooling1d_118/Mean:0' shape=(?, 191) dtype=float32>, <tf.Tensor 'global_average_pooling1d_119/Mean:0' shape=(?, 95) dtype=float32>, <tf.Tensor 'global_average_pooling1d_120/Mean:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'dense_cols_29:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 24s 20us/step - loss: 0.7582\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 21s 18us/step - loss: 0.2326\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 22s 18us/step - loss: 0.2127\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 22s 18us/step - loss: 0.2001\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 22s 19us/step - loss: 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7520169 8.777194\n",
      "score........................ 0.4314909857891073\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 738.9647\n",
      "Function value obtained: 0.4315\n",
      "Current minimum: 0.4232\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "parameters................... [80, 80, 3, 10, 19, 6, 160, 20, 31, 77, 500, 0.05819740347732745, 0.006939521554938218, 0.004797231587438435]\n",
      "[<tf.Tensor 'reshape_181/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_182/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_183/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_184/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_185/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_186/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'global_average_pooling1d_121/Mean:0' shape=(?, 160) dtype=float32>, <tf.Tensor 'global_average_pooling1d_122/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_123/Mean:0' shape=(?, 31) dtype=float32>, <tf.Tensor 'global_average_pooling1d_124/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_30:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.6025\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1860\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1630\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1482\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1371\n",
      "[<tf.Tensor 'reshape_187/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_188/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_189/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_190/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_191/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_192/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'global_average_pooling1d_125/Mean:0' shape=(?, 160) dtype=float32>, <tf.Tensor 'global_average_pooling1d_126/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_127/Mean:0' shape=(?, 31) dtype=float32>, <tf.Tensor 'global_average_pooling1d_128/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_31:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.6549\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1863\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1642\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1502\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1392\n",
      "[<tf.Tensor 'reshape_193/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_194/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_195/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_196/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_197/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_198/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'global_average_pooling1d_129/Mean:0' shape=(?, 160) dtype=float32>, <tf.Tensor 'global_average_pooling1d_130/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_131/Mean:0' shape=(?, 31) dtype=float32>, <tf.Tensor 'global_average_pooling1d_132/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_32:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 17s 14us/step - loss: 0.6460\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1852\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1632\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1488\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 14s 12us/step - loss: 0.1383\n",
      "[<tf.Tensor 'reshape_199/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_200/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_201/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_202/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_203/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_204/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'global_average_pooling1d_133/Mean:0' shape=(?, 160) dtype=float32>, <tf.Tensor 'global_average_pooling1d_134/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_135/Mean:0' shape=(?, 31) dtype=float32>, <tf.Tensor 'global_average_pooling1d_136/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_33:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.5846\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1817\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1592\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1448\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1340\n",
      "[<tf.Tensor 'reshape_205/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_206/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_207/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_208/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_209/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_210/Reshape:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'global_average_pooling1d_137/Mean:0' shape=(?, 160) dtype=float32>, <tf.Tensor 'global_average_pooling1d_138/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_139/Mean:0' shape=(?, 31) dtype=float32>, <tf.Tensor 'global_average_pooling1d_140/Mean:0' shape=(?, 77) dtype=float32>, <tf.Tensor 'dense_cols_34:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.5653\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1842\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1606\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1454\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 14s 12us/step - loss: 0.1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6026732 9.239472\n",
      "score........................ 0.4241102378412022\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 550.4278\n",
      "Function value obtained: 0.4241\n",
      "Current minimum: 0.4232\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "parameters................... [8, 57, 3, 9, 19, 74, 66, 24, 61, 26, 71, 0.4838206764920833, 0.007548698571006923, 0.00932186043739471]\n",
      "[<tf.Tensor 'reshape_211/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_212/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_213/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_214/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_215/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_216/Reshape:0' shape=(?, 74) dtype=float32>, <tf.Tensor 'global_average_pooling1d_141/Mean:0' shape=(?, 66) dtype=float32>, <tf.Tensor 'global_average_pooling1d_142/Mean:0' shape=(?, 24) dtype=float32>, <tf.Tensor 'global_average_pooling1d_143/Mean:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_144/Mean:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'dense_cols_35:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 16s 13us/step - loss: 0.5560\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2412\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2224\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2119\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2050\n",
      "[<tf.Tensor 'reshape_217/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_218/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_219/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_220/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_221/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_222/Reshape:0' shape=(?, 74) dtype=float32>, <tf.Tensor 'global_average_pooling1d_145/Mean:0' shape=(?, 66) dtype=float32>, <tf.Tensor 'global_average_pooling1d_146/Mean:0' shape=(?, 24) dtype=float32>, <tf.Tensor 'global_average_pooling1d_147/Mean:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_148/Mean:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'dense_cols_36:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 16s 14us/step - loss: 0.5639\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2442\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2246\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2134\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2064\n",
      "[<tf.Tensor 'reshape_223/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_224/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_225/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_226/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_227/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_228/Reshape:0' shape=(?, 74) dtype=float32>, <tf.Tensor 'global_average_pooling1d_149/Mean:0' shape=(?, 66) dtype=float32>, <tf.Tensor 'global_average_pooling1d_150/Mean:0' shape=(?, 24) dtype=float32>, <tf.Tensor 'global_average_pooling1d_151/Mean:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_152/Mean:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'dense_cols_37:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185326/1185326 [==============================] - 16s 14us/step - loss: 0.5681\n",
      "Epoch 2/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2386\n",
      "Epoch 3/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2203\n",
      "Epoch 4/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2100\n",
      "Epoch 5/5\n",
      "1185326/1185326 [==============================] - 13s 11us/step - loss: 0.2031\n",
      "[<tf.Tensor 'reshape_229/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_230/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_231/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_232/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_233/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_234/Reshape:0' shape=(?, 74) dtype=float32>, <tf.Tensor 'global_average_pooling1d_153/Mean:0' shape=(?, 66) dtype=float32>, <tf.Tensor 'global_average_pooling1d_154/Mean:0' shape=(?, 24) dtype=float32>, <tf.Tensor 'global_average_pooling1d_155/Mean:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_156/Mean:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'dense_cols_38:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 17s 14us/step - loss: 0.5592\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.2327\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.2156\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.2060\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.1994\n",
      "[<tf.Tensor 'reshape_235/Reshape:0' shape=(?, 8) dtype=float32>, <tf.Tensor 'reshape_236/Reshape:0' shape=(?, 57) dtype=float32>, <tf.Tensor 'reshape_237/Reshape:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'reshape_238/Reshape:0' shape=(?, 9) dtype=float32>, <tf.Tensor 'reshape_239/Reshape:0' shape=(?, 19) dtype=float32>, <tf.Tensor 'reshape_240/Reshape:0' shape=(?, 74) dtype=float32>, <tf.Tensor 'global_average_pooling1d_157/Mean:0' shape=(?, 66) dtype=float32>, <tf.Tensor 'global_average_pooling1d_158/Mean:0' shape=(?, 24) dtype=float32>, <tf.Tensor 'global_average_pooling1d_159/Mean:0' shape=(?, 61) dtype=float32>, <tf.Tensor 'global_average_pooling1d_160/Mean:0' shape=(?, 26) dtype=float32>, <tf.Tensor 'dense_cols_39:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n",
      "1185327/1185327 [==============================] - 16s 14us/step - loss: 0.5573\n",
      "Epoch 2/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.2440\n",
      "Epoch 3/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.2254\n",
      "Epoch 4/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.2146\n",
      "Epoch 5/5\n",
      "1185327/1185327 [==============================] - 13s 11us/step - loss: 0.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8476997 7.9515457\n",
      "score........................ 0.437648122690143\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 533.2975\n",
      "Function value obtained: 0.4376\n",
      "Current minimum: 0.4232\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "parameters................... [80, 5, 10, 2, 2, 80, 20, 200, 100, 10, 50, 0.01, 0.001, 1e-05]\n",
      "[<tf.Tensor 'reshape_241/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'reshape_242/Reshape:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'reshape_243/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_244/Reshape:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'reshape_245/Reshape:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'reshape_246/Reshape:0' shape=(?, 80) dtype=float32>, <tf.Tensor 'global_average_pooling1d_161/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_162/Mean:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'global_average_pooling1d_163/Mean:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'global_average_pooling1d_164/Mean:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'dense_cols_40:0' shape=(?, 17) dtype=float32>]\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,100]\n\t [[Node: training_40/Adam/Variable_27/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@training_40/Adam/Variable_27\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_40/Adam/Variable_27, training_40/Adam/Const_10)]]\n\nCaused by op 'training_40/Adam/Variable_27/Assign', defined at:\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-f75e4156b40a>\", line 3, in <module>\n    res = optimize_nn(train_data, np.log1p(train_data.price), cvlist)\n  File \"<ipython-input-18-f3591f54c88c>\", line 75, in optimize_nn\n    verbose=True)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/skopt/optimizer/gp.py\", line 219, in gp_minimize\n    callback=callback, n_jobs=n_jobs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/skopt/optimizer/base.py\", line 250, in base_minimize\n    next_y = func(next_x)\n  File \"<ipython-input-18-f3591f54c88c>\", line 55, in objective\n    preds = cross_val_predict(nnet2, X, y, cv=cvlist, verbose=1, n_jobs=1, pre_dispatch=None)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 680, in cross_val_predict\n    for train, test in cv.split(X, y, groups))\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 753, in _fit_and_predict\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"<ipython-input-12-1799dcf5bd39>\", line 143, in fit\n    verbose=self.verbose, shuffle=True)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1634, in fit\n    self._make_train_function()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 428, in get_updates\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 428, in <listcomp>\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 681, in zeros\n    dtype, name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 385, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,100]\n\t [[Node: training_40/Adam/Variable_27/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@training_40/Adam/Variable_27\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_40/Adam/Variable_27, training_40/Adam/Const_10)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,100]\n\t [[Node: training_40/Adam/Variable_27/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@training_40/Adam/Variable_27\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_40/Adam/Variable_27, training_40/Adam/Const_10)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f75e4156b40a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcvlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m786\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-f3591f54c88c>\u001b[0m in \u001b[0;36moptimize_nn\u001b[0;34m(X, y, cvlist, save_path)\u001b[0m\n\u001b[1;32m     73\u001b[0m                       \u001b[0mn_random_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# the number of random initialization points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                       \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m786\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                      verbose=True) \n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# no need to fit a model on the last iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_calls\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-f3591f54c88c>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m#scores = cross_val_score(nnet2, X, y, cv=cvlist, verbose=1, scoring=rmse_sklearn, n_jobs=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#                         pre_dispatch=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnet2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#score = np.mean(scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    678\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    679\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 680\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1799dcf5bd39>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             self.model.fit(self._splitX(X), y, batch_size=self.batchsize, epochs=self.epochs,\n\u001b[0;32m--> 143\u001b[0;31m                verbose=self.verbose, shuffle=True)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2357\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,100]\n\t [[Node: training_40/Adam/Variable_27/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@training_40/Adam/Variable_27\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_40/Adam/Variable_27, training_40/Adam/Const_10)]]\n\nCaused by op 'training_40/Adam/Variable_27/Assign', defined at:\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-f75e4156b40a>\", line 3, in <module>\n    res = optimize_nn(train_data, np.log1p(train_data.price), cvlist)\n  File \"<ipython-input-18-f3591f54c88c>\", line 75, in optimize_nn\n    verbose=True)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/skopt/optimizer/gp.py\", line 219, in gp_minimize\n    callback=callback, n_jobs=n_jobs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/skopt/optimizer/base.py\", line 250, in base_minimize\n    next_y = func(next_x)\n  File \"<ipython-input-18-f3591f54c88c>\", line 55, in objective\n    preds = cross_val_predict(nnet2, X, y, cv=cvlist, verbose=1, n_jobs=1, pre_dispatch=None)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 680, in cross_val_predict\n    for train, test in cv.split(X, y, groups))\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 753, in _fit_and_predict\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"<ipython-input-12-1799dcf5bd39>\", line 143, in fit\n    verbose=self.verbose, shuffle=True)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1634, in fit\n    self._make_train_function()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 428, in get_updates\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 428, in <listcomp>\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 681, in zeros\n    dtype, name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 385, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,100]\n\t [[Node: training_40/Adam/Variable_27/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@training_40/Adam/Variable_27\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_40/Adam/Variable_27, training_40/Adam/Const_10)]]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "cvlist = list(KFold(5, random_state=786).split(train_data))\n",
    "res = optimize_nn(train_data, np.log1p(train_data.price), cvlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EM_NNRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-227c0d825127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nnet2 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0membed_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mtext_embed_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item_description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item_desc2gram'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mtext_embed_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mtext_embed_seq_lens\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EM_NNRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "nnet2 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n",
    "                  embed_dims=[(6000, 30),(1500, 25), (5,4), (15,4), (120, 10), (900, 20)],\n",
    "                  text_embed_cols=['name', 'item_description', 'item_desc2gram', 'item_name'],\n",
    "                  text_embed_dims=[(20000, 30), (100000, 30), (10000, 30), (20000, 30)],\n",
    "                  text_embed_seq_lens =[7, 80, 20, 20],\n",
    "                  #text_embed_tokenizers = [tok_name, tok_desc, tok_desc2],\n",
    "                  dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts'],\n",
    "                  epochs=5,\n",
    "                  batchsize=2048 ,\n",
    "                  num_layers = 1,\n",
    "                  layer_dropouts=[0.1],\n",
    "                  layer_dims=[100],\n",
    "                  seed=2,\n",
    "                  val_size=0.02\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_211/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_212/Reshape:0' shape=(?, 25) dtype=float32>, <tf.Tensor 'reshape_213/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_214/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_215/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_216/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_141/Mean:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'global_average_pooling1d_142/Mean:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'global_average_pooling1d_143/Mean:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'global_average_pooling1d_144/Mean:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'dense_cols_66:0' shape=(?, 17) dtype=float32>]\n",
      "(1161619, 35) (23707, 35) (1161619,) (23707,)\n",
      "Train on 1161619 samples, validate on 23707 samples\n",
      "Epoch 1/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.5079Epoch 00001: val_loss improved from inf to 0.22992, saving model to embed_NN_2.check\n",
      "1161619/1161619 [==============================] - 26s 22us/step - loss: 0.5068 - val_loss: 0.2299\n",
      "Epoch 2/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1933Epoch 00002: val_loss improved from 0.22992 to 0.18494, saving model to embed_NN_2.check\n",
      "1161619/1161619 [==============================] - 12s 10us/step - loss: 0.1933 - val_loss: 0.1849\n",
      "Epoch 3/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1724Epoch 00003: val_loss improved from 0.18494 to 0.18494, saving model to embed_NN_2.check\n",
      "1161619/1161619 [==============================] - 12s 10us/step - loss: 0.1725 - val_loss: 0.1849\n",
      "Epoch 4/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1601Epoch 00004: val_loss improved from 0.18494 to 0.18203, saving model to embed_NN_2.check\n",
      "1161619/1161619 [==============================] - 11s 10us/step - loss: 0.1601 - val_loss: 0.1820\n",
      "Epoch 5/5\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1512Epoch 00005: val_loss improved from 0.18203 to 0.18160, saving model to embed_NN_2.check\n",
      "1161619/1161619 [==============================] - 12s 10us/step - loss: 0.1512 - val_loss: 0.1816\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-1b392cb55e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moof_preds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnet2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_preds2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    678\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    679\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 680\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'decision_function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_log_proba'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-876e2a9385df>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embed_NN_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_splitX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# Early return if compilation is not required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                              ' elements.')\n\u001b[1;32m   3142\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2250\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oof_preds2 = cross_val_predict(nnet2, X, y, verbose=10, cv=cvlist)\n",
    "score = rmse(y, oof_preds2)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_85/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_86/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_87/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_88/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_89/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_90/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_57/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_58/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_59/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_60/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'dense_cols_25:0' shape=(?, 17) dtype=float32>]\n",
      "(1161619, 35) (23707, 35) (1161619,) (23707,)\n",
      "Train on 1161619 samples, validate on 23707 samples\n",
      "Epoch 1/4\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.5970Epoch 00001: val_loss improved from inf to 0.22496, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 19s 17us/step - loss: 0.5955 - val_loss: 0.2250\n",
      "Epoch 2/4\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1755Epoch 00002: val_loss improved from 0.22496 to 0.17857, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1755 - val_loss: 0.1786\n",
      "Epoch 3/4\n",
      "1161216/1161619 [============================>.] - ETA: 0s - loss: 0.1538Epoch 00003: val_loss did not improve\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1538 - val_loss: 0.1814\n",
      "Epoch 4/4\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1413Epoch 00004: val_loss improved from 0.17857 to 0.17097, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1413 - val_loss: 0.1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_91/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_92/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_93/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_94/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_95/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_96/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_61/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_62/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_63/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_64/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'dense_cols_27:0' shape=(?, 17) dtype=float32>]\n",
      "(1161619, 35) (23707, 35) (1161619,) (23707,)\n",
      "Train on 1161619 samples, validate on 23707 samples\n",
      "Epoch 1/4\n",
      "1161216/1161619 [============================>.] - ETA: 0s - loss: 0.5604Epoch 00001: val_loss improved from inf to 0.27157, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 19s 17us/step - loss: 0.5603 - val_loss: 0.2716\n",
      "Epoch 2/4\n",
      "1159168/1161619 [============================>.] - ETA: 0s - loss: 0.1754Epoch 00002: val_loss improved from 0.27157 to 0.19065, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1753 - val_loss: 0.1907\n",
      "Epoch 3/4\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1533Epoch 00003: val_loss improved from 0.19065 to 0.17058, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1533 - val_loss: 0.1706\n",
      "Epoch 4/4\n",
      "1161216/1161619 [============================>.] - ETA: 0s - loss: 0.1407Epoch 00004: val_loss did not improve\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1407 - val_loss: 0.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_97/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_98/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_99/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_100/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_101/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_102/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_65/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_66/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_67/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_68/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'dense_cols_29:0' shape=(?, 17) dtype=float32>]\n",
      "(1161619, 35) (23707, 35) (1161619,) (23707,)\n",
      "Train on 1161619 samples, validate on 23707 samples\n",
      "Epoch 1/4\n",
      "1161216/1161619 [============================>.] - ETA: 0s - loss: 0.5594Epoch 00001: val_loss improved from inf to 0.22372, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 20s 17us/step - loss: 0.5592 - val_loss: 0.2237\n",
      "Epoch 2/4\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1748Epoch 00002: val_loss improved from 0.22372 to 0.18285, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1747 - val_loss: 0.1829\n",
      "Epoch 3/4\n",
      "1157120/1161619 [============================>.] - ETA: 0s - loss: 0.1528Epoch 00003: val_loss improved from 0.18285 to 0.17608, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1528 - val_loss: 0.1761\n",
      "Epoch 4/4\n",
      "1161216/1161619 [============================>.] - ETA: 0s - loss: 0.1403Epoch 00004: val_loss improved from 0.17608 to 0.17089, saving model to embed_NN_3.check\n",
      "1161619/1161619 [==============================] - 14s 12us/step - loss: 0.1403 - val_loss: 0.1709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_103/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_104/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_105/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_106/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_107/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_108/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_69/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_70/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_71/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_72/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'dense_cols_31:0' shape=(?, 17) dtype=float32>]\n",
      "(1161620, 35) (23707, 35) (1161620,) (23707,)\n",
      "Train on 1161620 samples, validate on 23707 samples\n",
      "Epoch 1/4\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.5585Epoch 00001: val_loss improved from inf to 0.22848, saving model to embed_NN_3.check\n",
      "1161620/1161620 [==============================] - 20s 18us/step - loss: 0.5571 - val_loss: 0.2285\n",
      "Epoch 2/4\n",
      "1159168/1161620 [============================>.] - ETA: 0s - loss: 0.1747Epoch 00002: val_loss improved from 0.22848 to 0.17922, saving model to embed_NN_3.check\n",
      "1161620/1161620 [==============================] - 14s 12us/step - loss: 0.1747 - val_loss: 0.1792\n",
      "Epoch 3/4\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.1532Epoch 00003: val_loss improved from 0.17922 to 0.17278, saving model to embed_NN_3.check\n",
      "1161620/1161620 [==============================] - 13s 12us/step - loss: 0.1532 - val_loss: 0.1728\n",
      "Epoch 4/4\n",
      "1161216/1161620 [============================>.] - ETA: 0s - loss: 0.1409Epoch 00004: val_loss did not improve\n",
      "1161620/1161620 [==============================] - 13s 12us/step - loss: 0.1409 - val_loss: 0.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_109/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_110/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_111/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_112/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_113/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_114/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'global_average_pooling1d_73/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_74/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_75/Mean:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'global_average_pooling1d_76/Mean:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'dense_cols_33:0' shape=(?, 17) dtype=float32>]\n",
      "(1161620, 35) (23707, 35) (1161620,) (23707,)\n",
      "Train on 1161620 samples, validate on 23707 samples\n",
      "Epoch 1/4\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.5359Epoch 00001: val_loss improved from inf to 0.24006, saving model to embed_NN_3.check\n",
      "1161620/1161620 [==============================] - 21s 18us/step - loss: 0.5346 - val_loss: 0.2401\n",
      "Epoch 2/4\n",
      "1159168/1161620 [============================>.] - ETA: 0s - loss: 0.1784Epoch 00002: val_loss improved from 0.24006 to 0.17663, saving model to embed_NN_3.check\n",
      "1161620/1161620 [==============================] - 14s 12us/step - loss: 0.1784 - val_loss: 0.1766\n",
      "Epoch 3/4\n",
      "1157120/1161620 [============================>.] - ETA: 0s - loss: 0.1564Epoch 00003: val_loss did not improve\n",
      "1161620/1161620 [==============================] - 14s 12us/step - loss: 0.1564 - val_loss: 0.1804\n",
      "Epoch 4/4\n",
      "1161216/1161620 [============================>.] - ETA: 0s - loss: 0.1440Epoch 00004: val_loss improved from 0.17663 to 0.17199, saving model to embed_NN_3.check\n",
      "1161620/1161620 [==============================] - 14s 12us/step - loss: 0.1440 - val_loss: 0.1720\n",
      "0.3729204 8.352561\n",
      "0.41859579758955956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.7min finished\n"
     ]
    }
   ],
   "source": [
    "nnet3 = EM_NNRegressor(embed_cols=['brand_name','category_name','item_condition_id', 'cat1', 'cat2', 'cat3'], \n",
    "                  embed_dims=[(6000, 30),(1500, 20), (5,4), (15,4), (120, 10), (900, 20)],\n",
    "                  text_embed_cols=['name', 'item_description', 'item_desc2gram', 'item_name'],\n",
    "                  text_embed_dims=[(20000, 50), (100000, 50), (10000, 50), (20000, 20)],\n",
    "                  text_embed_seq_lens =[7, 80, 20, 20],\n",
    "                  #text_embed_tokenizers = [tok_name, tok_desc, tok_desc2],\n",
    "                  dense_cols=['shipping', 'desc_words', 'desc_chars', 'name_chars',\n",
    "                                'iphone_case', 'iphone6', 'iphone6p',\n",
    "                                'iphone5', 'iphone5p', 'iphone7', 'iphone7p', 'unlocked_phone',\n",
    "                              'brand_counts', 'cat_counts',\n",
    "                                   'cat1_counts', 'cat2_counts', 'cat3_counts'],\n",
    "                  epochs=4,\n",
    "                  batchsize=2048 ,\n",
    "                  num_layers = 1,\n",
    "                  layer_dropouts=[0.2],\n",
    "                  layer_dims=[200],\n",
    "                  seed=3,\n",
    "                  val_size=0.02,\n",
    "                 )\n",
    "oof_preds3 = cross_val_predict(nnet3, X, y, verbose=10, cv=cvlist)\n",
    "score = rmse(y, oof_preds3)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean, gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481658,)\n",
      "0.8430702 8.256827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4071790911499989"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_preds = np.mean(np.hstack((oof_preds1, oof_preds2, oof_preds3)), axis=1)\n",
    "print(oof_preds.shape)\n",
    "rmse(y, oof_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25b3789e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.distplot(oof_preds)\n",
    "sns.distplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481658, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   43.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.988219376342803 4.961022181829234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   54.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   54.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4244249992307715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=50, max_depth=3, n_jobs=-1, min_samples_leaf=50)\n",
    "oof_X = np.hstack((oof_preds1, oof_preds2, oof_preds3))\n",
    "print(oof_X.shape)\n",
    "oof2 = cross_val_predict(rfr, oof_X, y , cv=5, verbose=10)\n",
    "rmse(y, oof2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding GRU - worsened performance\n",
    "#Flatten - worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_269/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_270/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_271/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_272/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_273/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_274/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_275/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_276/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_277/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_42:0' shape=(?, 21) dtype=float32>]\n",
      "(1444616, 32) (37042, 32) (1444616,) (37042,)\n",
      "Train on 1444616 samples, validate on 37042 samples\n",
      "Epoch 1/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.4759Epoch 00001: val_loss improved from inf to 0.21140, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 27s 19us/step - loss: 0.4757 - val_loss: 0.2114\n",
      "Epoch 2/5\n",
      "1441792/1444616 [============================>.] - ETA: 0s - loss: 0.1769Epoch 00002: val_loss improved from 0.21140 to 0.17565, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1769 - val_loss: 0.1757\n",
      "Epoch 3/5\n",
      "1441792/1444616 [============================>.] - ETA: 0s - loss: 0.1592Epoch 00003: val_loss improved from 0.17565 to 0.16952, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1592 - val_loss: 0.1695\n",
      "Epoch 4/5\n",
      "1441792/1444616 [============================>.] - ETA: 0s - loss: 0.1497Epoch 00004: val_loss improved from 0.16952 to 0.16942, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1496 - val_loss: 0.1694\n",
      "Epoch 5/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.1433Epoch 00005: val_loss improved from 0.16942 to 0.16762, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1433 - val_loss: 0.1676\n",
      "Predicting on test data\n"
     ]
    }
   ],
   "source": [
    "nnet1.fit(train_data, np.log1p(train_data.price) )\n",
    "print(\"Predicting on test data\")\n",
    "#test_preds1 = nnet1.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_55/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_56/Reshape:0' shape=(?, 25) dtype=float32>, <tf.Tensor 'reshape_57/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_58/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_59/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_60/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_61/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_62/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_63/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_11:0' shape=(?, 17) dtype=float32>]\n",
      "(1452024, 32) (29634, 32) (1452024,) (29634,)\n",
      "Train on 1452024 samples, validate on 29634 samples\n",
      "Epoch 1/6\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.4870Epoch 00001: val_loss improved from inf to 0.21299, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 18s 12us/step - loss: 0.4859 - val_loss: 0.2130\n",
      "Epoch 2/6\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.2105Epoch 00002: val_loss improved from 0.21299 to 0.18757, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 15s 10us/step - loss: 0.2104 - val_loss: 0.1876\n",
      "Epoch 3/6\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1884Epoch 00003: val_loss improved from 0.18757 to 0.18330, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 15s 10us/step - loss: 0.1884 - val_loss: 0.1833\n",
      "Epoch 4/6\n",
      "1449984/1452024 [============================>.] - ETA: 0s - loss: 0.1747Epoch 00004: val_loss improved from 0.18330 to 0.18075, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 15s 10us/step - loss: 0.1747 - val_loss: 0.1807\n",
      "Epoch 5/6\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1650Epoch 00005: val_loss improved from 0.18075 to 0.17968, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 15s 10us/step - loss: 0.1650 - val_loss: 0.1797\n",
      "Epoch 6/6\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1574Epoch 00006: val_loss improved from 0.17968 to 0.17811, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 15s 10us/step - loss: 0.1574 - val_loss: 0.1781\n",
      "Predicting on test data\n"
     ]
    }
   ],
   "source": [
    "nnet2.fit(train_data, np.log1p(train_data.price) )\n",
    "print(\"Predicting on test data\")\n",
    "test_preds2 = nnet2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reshape_136/Reshape:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'reshape_137/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_138/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_139/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_140/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_141/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_142/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_143/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_144/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_30:0' shape=(?, 21) dtype=float32>]\n",
      "(1444616, 32) (37042, 32) (1444616,) (37042,)\n",
      "Train on 1444616 samples, validate on 37042 samples\n",
      "Epoch 1/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.5105Epoch 00001: val_loss improved from inf to 0.20131, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 24s 17us/step - loss: 0.5103 - val_loss: 0.2013\n",
      "Epoch 2/5\n",
      "1439744/1444616 [============================>.] - ETA: 0s - loss: 0.1957Epoch 00002: val_loss improved from 0.20131 to 0.17799, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1956 - val_loss: 0.1780\n",
      "Epoch 3/5\n",
      "1439744/1444616 [============================>.] - ETA: 0s - loss: 0.1730Epoch 00003: val_loss improved from 0.17799 to 0.17397, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1730 - val_loss: 0.1740\n",
      "Epoch 4/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.1602Epoch 00004: val_loss improved from 0.17397 to 0.17274, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1602 - val_loss: 0.1727\n",
      "Epoch 5/5\n",
      "1443840/1444616 [============================>.] - ETA: 0s - loss: 0.1503Epoch 00005: val_loss improved from 0.17274 to 0.17062, saving model to embed_NN_1.check\n",
      "1444616/1444616 [==============================] - 18s 12us/step - loss: 0.1503 - val_loss: 0.1706\n",
      "Predicting on test data\n",
      "[<tf.Tensor 'reshape_145/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_146/Reshape:0' shape=(?, 25) dtype=float32>, <tf.Tensor 'reshape_147/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_148/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_149/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_150/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_151/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_152/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_153/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'dense_cols_32:0' shape=(?, 17) dtype=float32>]\n",
      "(1452024, 32) (29634, 32) (1452024,) (29634,)\n",
      "Train on 1452024 samples, validate on 29634 samples\n",
      "Epoch 1/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.5018Epoch 00001: val_loss improved from inf to 0.20689, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 21s 15us/step - loss: 0.5006 - val_loss: 0.2069\n",
      "Epoch 2/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1954Epoch 00002: val_loss improved from 0.20689 to 0.18119, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 15s 10us/step - loss: 0.1954 - val_loss: 0.1812\n",
      "Epoch 3/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1744Epoch 00003: val_loss improved from 0.18119 to 0.17511, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 14s 10us/step - loss: 0.1743 - val_loss: 0.1751\n",
      "Epoch 4/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1621Epoch 00004: val_loss improved from 0.17511 to 0.17479, saving model to embed_NN_2.check\n",
      "1452024/1452024 [==============================] - 14s 10us/step - loss: 0.1621 - val_loss: 0.1748\n",
      "Predicting on test data\n",
      "[<tf.Tensor 'reshape_154/Reshape:0' shape=(?, 30) dtype=float32>, <tf.Tensor 'reshape_155/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_156/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_157/Reshape:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'reshape_158/Reshape:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'reshape_159/Reshape:0' shape=(?, 20) dtype=float32>, <tf.Tensor 'reshape_160/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_161/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'reshape_162/Reshape:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'dense_cols_34:0' shape=(?, 17) dtype=float32>]\n",
      "(1452024, 32) (29634, 32) (1452024,) (29634,)\n",
      "Train on 1452024 samples, validate on 29634 samples\n",
      "Epoch 1/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.5142Epoch 00001: val_loss improved from inf to 0.21044, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 24s 17us/step - loss: 0.5130 - val_loss: 0.2104\n",
      "Epoch 2/4\n",
      "1447936/1452024 [============================>.] - ETA: 0s - loss: 0.2053Epoch 00002: val_loss improved from 0.21044 to 0.18658, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.2053 - val_loss: 0.1866\n",
      "Epoch 3/4\n",
      "1449984/1452024 [============================>.] - ETA: 0s - loss: 0.1824Epoch 00003: val_loss improved from 0.18658 to 0.17833, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.1824 - val_loss: 0.1783\n",
      "Epoch 4/4\n",
      "1445888/1452024 [============================>.] - ETA: 0s - loss: 0.1704Epoch 00004: val_loss improved from 0.17833 to 0.17602, saving model to embed_NN_3.check\n",
      "1452024/1452024 [==============================] - 17s 12us/step - loss: 0.1704 - val_loss: 0.1760\n",
      "Predicting on test data\n",
      "Write out submission\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "nnet3.fit(train_data, np.log1p(train_data.price) )\n",
    "print(\"Predicting on test data\")\n",
    "test_preds3 = nnet3.predict(test_data)\n",
    "\n",
    "test_preds = (1/3)*(test_preds1 + test_preds2 + test_preds3)\n",
    "print(\"Write out submission\")\n",
    "submission: pd.DataFrame = test_data[['test_id']]\n",
    "submission['price'] = np.expm1(test_preds)\n",
    "submission.price = submission.price.clip(3, 2000)\n",
    "submission.to_csv(\"embedding_nn_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
