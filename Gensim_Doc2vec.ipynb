{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling categorical variables...\n",
      "CPU times: user 19.7 s, sys: 1.08 s, total: 20.8 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def to_categorical(dataset):\n",
    "    dataset['category_name'] = dataset['category_name'].astype('category')\n",
    "    dataset['brand_name'] = dataset['brand_name'].astype('category')\n",
    "    #dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')\n",
    "    return dataset\n",
    "    \n",
    "df_train = pd.read_csv('../input/train.tsv', sep='\\t')\n",
    "df_test = pd.read_csv('../input/test.tsv', sep='\\t')\n",
    "\n",
    "df_train['target'] = np.log1p(df_train['price'])\n",
    "\n",
    "df_train[\"category_name\"].fillna(value = \"unk_category\", inplace = True)\n",
    "df_train[\"item_description\"].fillna(value = \"missing\", inplace = True)\n",
    "df_train[\"brand_name\"].fillna(value = \"unk_brand\", inplace = True)\n",
    "df_train[\"name\"].fillna(value = \"unk_name\", inplace = True)\n",
    "\n",
    "df_test[\"category_name\"].fillna(value = \"unk_category\", inplace = True)\n",
    "df_test[\"item_description\"].fillna(value = \"missing\", inplace = True)\n",
    "df_test[\"brand_name\"].fillna(value = \"unk_brand\", inplace = True)\n",
    "df_test[\"name\"].fillna(value = \"unk_name\", inplace = True)\n",
    "\n",
    "df_train = to_categorical(df_train)\n",
    "df_test = to_categorical(df_test)\n",
    "\n",
    "print(\"Handling categorical variables...\")\n",
    "le = LabelEncoder()\n",
    "\n",
    "category = np.hstack([df_train.category_name, df_test.category_name])\n",
    "\n",
    "c = Counter(category)\n",
    "category_dict = {}\n",
    "for i in c:\n",
    "    if c[i] < 100:\n",
    "        category_dict[i] = \"unk_category\"\n",
    "        \n",
    "df_train.category_name = df_train.category_name.apply(lambda x: category_dict[x] if x in category_dict else x)\n",
    "df_test.category_name = df_test.category_name.apply(lambda x: category_dict[x] if x in category_dict else x)\n",
    "\n",
    "le.fit(np.hstack([df_train.category_name, df_test.category_name]))\n",
    "df_train['category'] = le.transform(df_train.category_name)\n",
    "df_test['category'] = le.transform(df_test.category_name)\n",
    "\n",
    "le.fit(np.hstack([df_train.brand_name, df_test.brand_name]))\n",
    "df_train['brand'] = le.transform(df_train.brand_name)\n",
    "df_test['brand'] = le.transform(df_test.brand_name)\n",
    "del le, df_train['brand_name'], df_test['brand_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 19s, sys: 527 ms, total: 4min 20s\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lmtz = WordNetLemmatizer()\n",
    "df_train.item_description = df_train.item_description.apply(lambda x: \" \".join(lmtz.lemmatize(i) for i in x.split()))\n",
    "df_test.item_description = df_test.item_description.apply(lambda x: \" \".join(lmtz.lemmatize(i) for i in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 445 ms, total: 2.09 s\n",
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "document = [sentence for sentence in df_train.item_description.values+\" \"+df_train.name.values + \" \"+ df_train.category_name.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abk0005/Competitions/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 5s, sys: 1min 17s, total: 14min 22s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "documents = []\n",
    "for item_no,sentence in enumerate(document):\n",
    "    documents.append(LabeledSentence(sentence.split(), [\"label\" + '_%s' % item_no]))\n",
    "\n",
    "# train the model\n",
    "model_doc2vec = Doc2Vec(documents, size=150, window=4, min_count=10, seed = 11, sample = 1e-4, alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming text to seq...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>seq_text</th>\n",
       "      <th>seq_item_description</th>\n",
       "      <th>seq_name</th>\n",
       "      <th>seq_category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>371</td>\n",
       "      <td>5287</td>\n",
       "      <td>[73, 44, 70, 76]</td>\n",
       "      <td>[13, 86, 102]</td>\n",
       "      <td>[2478, 8729, 7993, 70, 91, 7, 205]</td>\n",
       "      <td>[73, 44, 70, 76]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and work l...</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>67</td>\n",
       "      <td>3889</td>\n",
       "      <td>[61, 946, 878, 3457, 2066]</td>\n",
       "      <td>[33, 2684, 11, 8, 51, 18, 1, 258, 65, 20, 1226...</td>\n",
       "      <td>[10654, 25140, 16087, 2684]</td>\n",
       "      <td>[61, 946, 878, 3457, 2066]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>623</td>\n",
       "      <td>4588</td>\n",
       "      <td>[2, 44, 72, 277]</td>\n",
       "      <td>[708, 69, 10, 3, 4599, 12, 239, 1, 3, 893, 577...</td>\n",
       "      <td>[7595, 10467, 277]</td>\n",
       "      <td>[2, 44, 72, 277]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "                                       category_name  price  shipping  \\\n",
       "0                                  Men/Tops/T-shirts   10.0         1   \n",
       "1  Electronics/Computers & Tablets/Components & P...   52.0         0   \n",
       "2                        Women/Tops & Blouses/Blouse   10.0         1   \n",
       "\n",
       "                                    item_description    target  category  \\\n",
       "0                                 No description yet  2.397895       371   \n",
       "1  This keyboard is in great condition and work l...  3.970292        67   \n",
       "2  Adorable top with a hint of lace and a key hol...  2.397895       623   \n",
       "\n",
       "   brand                    seq_text  \\\n",
       "0   5287            [73, 44, 70, 76]   \n",
       "1   3889  [61, 946, 878, 3457, 2066]   \n",
       "2   4588            [2, 44, 72, 277]   \n",
       "\n",
       "                                seq_item_description  \\\n",
       "0                                      [13, 86, 102]   \n",
       "1  [33, 2684, 11, 8, 51, 18, 1, 258, 65, 20, 1226...   \n",
       "2  [708, 69, 10, 3, 4599, 12, 239, 1, 3, 893, 577...   \n",
       "\n",
       "                             seq_name           seq_category_name  \n",
       "0  [2478, 8729, 7993, 70, 91, 7, 205]            [73, 44, 70, 76]  \n",
       "1         [10654, 25140, 16087, 2684]  [61, 946, 878, 3457, 2066]  \n",
       "2                  [7595, 10467, 277]            [2, 44, 72, 277]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "raw_text = np.hstack([df_train.category_name.str.lower(), \n",
    "                      df_train.item_description.str.lower(), \n",
    "                      df_train.name.str.lower()])\n",
    "\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "print(\"Transforming text to seq...\")\n",
    "df_train[\"seq_category_name\"] = tok_raw.texts_to_sequences(df_train.category_name.str.lower())\n",
    "df_test[\"seq_category_name\"] = tok_raw.texts_to_sequences(df_test.category_name.str.lower())\n",
    "df_train[\"seq_item_description\"] = tok_raw.texts_to_sequences(df_train.item_description.str.lower())\n",
    "df_test[\"seq_item_description\"] = tok_raw.texts_to_sequences(df_test.item_description.str.lower())\n",
    "df_train[\"seq_name\"] = tok_raw.texts_to_sequences(df_train.name.str.lower())\n",
    "df_test[\"seq_name\"] = tok_raw.texts_to_sequences(df_test.name.str.lower())\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CATEGORY = np.max([df_train.category.max(), df_test.category.max()])+1\n",
    "MAX_BRAND = np.max([df_train.brand.max(), df_test.brand.max()])+1\n",
    "MAX_CONDITION = np.max([df_train.item_condition_id.max(), \n",
    "                        df_test.item_condition_id.max()])+1\n",
    "MAX_NAME_SEQ = 20\n",
    "MAX_ITEM_DESC_SEQ = 60\n",
    "MAX_TEXT = np.max([np.max(df_train.seq_name.max())\n",
    "                   , np.max(df_test.seq_name.max())\n",
    "                   , np.max(df_train.seq_category_name.max())\n",
    "                   , np.max(df_test.seq_category_name.max())\n",
    "                   , np.max(df_train.seq_item_description.max())\n",
    "                   , np.max(df_test.seq_item_description.max())])+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 \\\n",
    "              for i, pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abk0005/Competitions/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dtrain, dtest = train_test_split(df_train, random_state = 11, train_size = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1453031 samples, validate on 14678 samples\n",
      "Epoch 1/2\n",
      "1453031/1453031 [==============================] - 126s 87us/step - loss: 0.4973 - val_loss: 0.3014\n",
      "Epoch 2/2\n",
      "1453031/1453031 [==============================] - 120s 82us/step - loss: 0.3352 - val_loss: 0.2926\n",
      "RMSLE error on dev test: 0.5285650761160501\n",
      "CPU times: user 25min 1s, sys: 1min 59s, total: 27min 1s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.layers import Input, Dropout, Dense, Activation, concatenate, Embedding, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping#, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        \"category\": np.array(dataset.category),\n",
    "        'brand': np.array(dataset.brand),\n",
    "        \"item_condition\":np.array(dataset.item_condition_id),\n",
    "        \"num_vars\":np.column_stack((np.array(dataset.shipping), model_doc2vec.docvecs.doctag_syn0[dataset.index]))\n",
    "        , 'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n",
    "        ,'item_desc': pad_sequences(dataset.seq_item_description\n",
    "                                    , maxlen=MAX_ITEM_DESC_SEQ)\n",
    "    }\n",
    "    return X\n",
    "    \n",
    "X = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dtest)\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    #Input\n",
    "    category = Input(shape = [1], name = \"category\")\n",
    "    brand = Input(shape = [1], name = \"brand\")\n",
    "    item_condition = Input(shape = [1], name = \"item_condition\")\n",
    "    num_vars = Input(shape = [X[\"num_vars\"].shape[1]], name = \"num_vars\")\n",
    "    \n",
    "    # Embed Layers\n",
    "    emb_category = Embedding(MAX_CATEGORY, 32)(category)\n",
    "    emb_brand = Embedding(MAX_BRAND, 128)(brand)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 2)(item_condition)\n",
    "    \n",
    "    # main_layer\n",
    "    main_l = concatenate([Flatten() (emb_category),\n",
    "                         Flatten() (emb_brand),\n",
    "                         Flatten() (emb_item_condition),\n",
    "                         num_vars])\n",
    "    main_l = Dense(1024, activation = \"relu\")(main_l)\n",
    "    main_l = Dropout(0.4)(main_l)\n",
    "    main_l = Dense(512, activation = \"relu\")(main_l)\n",
    "    main_l = Dropout(0.4)(main_l)\n",
    "    main_l = Dense(64, activation = \"relu\")(main_l)\n",
    "    main_l = Dropout(0.05)(main_l)\n",
    "    \n",
    "    output = Dense(1, activation = \"linear\")(main_l)\n",
    "    \n",
    "    model = Model([category, brand, item_condition, num_vars], output)\n",
    "\n",
    "    optimizer = optimizers.Adam()\n",
    "    model.compile(loss=\"mse\", \n",
    "                  optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def eval_model(model):\n",
    "    val_preds = model.predict(X_valid)\n",
    "    val_preds = np.expm1(val_preds)\n",
    "    \n",
    "    y_true = np.array(dtest.price.values)\n",
    "    y_pred = val_preds[:, 0]\n",
    "    v_rmsle = rmsle(y_true, y_pred)\n",
    "    print(\"RMSLE error on dev test: \"+str(v_rmsle))\n",
    "    return v_rmsle\n",
    "\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "\n",
    "epochs = 2\n",
    "BATCH_SIZE = 512 * 6\n",
    "steps = int(len(X['category'])/BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.001, 0.009\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "model = get_model()\n",
    "K.set_value(model.optimizer.lr, lr_init)\n",
    "K.set_value(model.optimizer.decay, lr_decay)\n",
    "\n",
    "history = model.fit(X, dtrain.target\n",
    "                    , epochs=epochs\n",
    "                    , batch_size=BATCH_SIZE\n",
    "                    , validation_split=0.01\n",
    "                    #, callbacks=[ModelCheckpoint(\"embed_NN_.check\", save_best_only=True)]\n",
    "                    , verbose=1\n",
    "                    )\n",
    "\n",
    "v_rmsle = eval_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
